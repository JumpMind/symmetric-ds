<?xml version="1.0" encoding="UTF-8"?>
<chapter version="5.0" xml:id="administration" xmlns="http://docbook.org/ns/docbook"
         xmlns:xlink="http://www.w3.org/1999/xlink"
         xmlns:xi="http://www.w3.org/2001/XInclude"
         xmlns:svg="http://www.w3.org/2000/svg"
         xmlns:ns="http://docbook.org/ns/docbook"
         xmlns:mml="http://www.w3.org/1998/Math/MathML"
         xmlns:html="http://www.w3.org/1999/xhtml">
    <title>Administration</title>
    
    <section id="solving-synchronization-issues">
        <title>Solving Synchronization Issues</title>
       
       <para>
       By design, whenever SymmetricDS encounters an issue with a synchronization, the batch containing the error is marked as being in
       an error state, and all subsequent batches <emphasis>for that particular channel to that particular node</emphasis> are held and not
       synchronized until the error batch is resolved.  SymmetricDS will retry the batch in error until the situation creating the
       error is resolved (or the data for the batch itself is changed).
       </para>
       
        <section id="solving-synchronization-issues-analysis">
        <title>Analyzing the Issue</title>
       
       <para>
       The first step in analyzing the cause of a failed batch is to locate information about the data in the batch, starting with  
       either <xref linkend="table_outgoing_batch" xrefstyle="table"/> or <xref linkend="table_incoming_batch" xrefstyle="table"/>.
       We'll use outgoing batches for the examples below.  To locate batches in error, use:
       <programlisting>select * from sym_outgoing_batch where error_flag=1;</programlisting>       
       Several useful pieces of information are available from this query:
       <itemizedlist>
       <listitem>
       The batch number of the failed batch, available in column <literal>BATCH_ID</literal>.
       </listitem>       
       <listitem>
       The node to which the batch is being sent, available in column <literal>NODE_ID</literal>.
       </listitem>
       <listitem>
       The channel to which the batch belongs, available in column <literal>CHANNEL_ID</literal>. 
       All subsequent batches on this channel to this node will be held until the error condition is resolved.
       </listitem>
       <listitem>
       The specific data id in the batch which is causing the failure, available in column <literal>FAILED_DATA_ID</literal>.
       </listitem>       
       <listitem>
       Any SQL message, SQL State, and SQL Codes being returned during the synchronization attempt, available in columns <literal>SQL_MESSAGE</literal>,
       <literal>SQL_STATE</literal>, and <literal>SQL_CODE</literal>, respectively.
       </listitem>
       </itemizedlist>
       </para>
       <note>
       Using the <literal>error_flag</literal> on the batch table, as shown above, is more reliable than using the
       <literal>status</literal> column.  The status column can change from 'ER' to a different status temporarily as
       the batch is retried.
       </note>
       <note>The query above will also show you any recent batches that
       were originally in error and were changed to be manually skipped.  See the end of  <xref linkend="solving-synchronization-issues-resolution" /> for more details.
       </note>
       <para>
       To get a full picture of the batch, you can query for information representing the complete 
       list of all data changes associated with the failed batch by joining
       <xref linkend="table_data" xrefstyle="table"/> and  <xref linkend="table_data_event" xrefstyle="table"/>, such as:
       <programlisting>select * from sym_data where data_id in 
        (select data_id from sym_data_event where batch_id='XXXXXX');</programlisting> 
       where XXXXXX is the batch id of the failing batch.
       </para>
       <para>
       This query returns a wealth of information about each data change in a batch, including:
       <itemizedlist>
       <listitem>
       The table involved in each data change, available in column <literal>TABLE_NAME</literal>,</listitem>
       <listitem>
       The event type (Update [U], Insert [I], or Delete [D]), available in column <literal>EVENT_TYPE</literal>,
       </listitem>
       <listitem>
       A comma separated list of the new data and (optionally) the old data, available in columns <literal>ROW_DATA</literal> and 
       <literal>OLD_DATA</literal>, respectively.
       </listitem>
       <listitem>
       The primary key data, available in column <literal>PK_DATA</literal>
       </listitem>
       <listitem>
       The channel id, trigger history information, transaction id if available, and other information.
       </listitem>
       </itemizedlist>
       </para>
       <para>
       More importantly, if you narrow your query to just the failed data id you can determine the exact data change that is causing the failure:       
       <programlisting>select * from sym_data where data_id in 
        (select failed_data_id from sym_outgoing_batch where batch_id='XXXXX');</programlisting>
       where XXXXXX is the batch that is failing.
       </para>
       <para>The queries above usually yield enough information to be able to determine why a
       particular batch is failing. Common reasons a batch might be failing include:
            <itemizedlist>
            <listitem>
            The schema at the destination has a column that is not nullable yet the source
            has the column defined as nullable and a data change was sent with the column as null.</listitem>
            <listitem>
            A foreign key constraint at the destination is preventing an insertion or update, which could be caused from
            data being deleted at the destination or the foreign key constraint is not in place at the source.
            </listitem>
            <listitem>
            The data size of a column on the destination is smaller than the data size in the source, and data that
            is too large for the destination has been synced.
            </listitem>
            </itemizedlist>
            </para>
                   
    </section>
            <section id="solving-synchronization-issues-resolution">
            <title>Resolving the Issue</title>
            
            <para>
            Once you have decided upon the cause of the issue, you'll have to decide the best course of action to fix the issue.  If, for example,
            the problem is due to a database schema mismatch, one possible solution would be to alter the destination database
            in such a way that the SQL error no longer occurs.  Whatever approach you take to remedy the issue, once you have
            made the change, on the next push or pull SymmetricDS will retry the batch
            and the channel's data will start flowing again.            
            </para>
            <para>
            If you have instead decided that the batch itself is wrong, or does not need synchronized, or you wish to remove a 
            particular data change from a batch, you do have the option of changing the data associated with the batch directly.
           
            <warning>
            Be cautious when using the following two approaches to resolve synchronization issues.  By far, the
            best approach to solving a synchronization error is to resolve what is truly causing the
            error at the destination database.  Skipping a batch or removing a data id as discussed below should be your
            solution of last resort, since doing so results in differences between the source and destination databases.
            </warning>
            
            Now that you've read the warning, if you <emphasis>still</emphasis> want to change the batch
            data itself, you do have several options, including:
            <itemizedlist>
                <listitem>Causing SymmetricDS to skip the batch completely.  This is accomplished by setting the
                batch's status to 'OK', as in:
                <programlisting>update sym_outgoing_batch set status='OK' where batch_id='XXXXXX'</programlisting>
                where XXXXXX is the failing batch. On the next pull or push, SymmetricDS will skip this batch since
                it now thinks the batch has already been synchronized.  Note that you can still distinguish between successful
                batches and ones that you've artificially marked as 'OK', since the <literal>error_flag</literal> column on
                the failed batch will still be set to '1' (in error).
                </listitem>
                <listitem>
                Removing the failing data id from the batch by deleting the corresponding row in <xref linkend="table_data_event" xrefstyle="table"/>.
                Eliminating the data id from the list of data ids in the batch will cause future synchronization attempts
                of the batch to no longer include that particular data change as part of the batch.  For example:
                  <programlisting>delete from sym_data_event where batch_id='XXXXXX' and data_id='YYYYYY'</programlisting>
                where XXXXXX is the failing batch and YYYYYY is the data id to longer be included in the batch.
                </listitem>
            </itemizedlist>
            </para>
   </section>
   </section>
    <section id="changing-triggers">
        <title>Changing Triggers</title>
        <para>
            A trigger row may be updated using SQL to change a synchronization definition.
            SymmetricDS will look for changes each night or whenever the Sync Triggers Job 
            is run (see below).  For example, a change to place the table <literal>price_changes</literal> 
            into the price channel would be accomplished with the following statement:
            <programlisting>
<![CDATA[update SYM_TRIGGER
set channel_id = 'price',
    last_update_by = 'jsmith',
    last_update_time = current_timestamp
where source_table_name = 'price_changes';
]]></programlisting>            
            All configuration should be managed centrally at the registration node.  If enabled, configuration 
            changes will be synchronized out to client nodes.  When trigger changes reach the client
            nodes the Sync Triggers Job will run automatically.
         </para>
         <para>   
            Centrally, the trigger changes will not take effect until the Sync Triggers Job runs.
            Instead of waiting for the Sync Triggers Job to run overnight after making a Trigger
            change, you can invoke the syncTriggers() method over JMX or simply restart the SymmetricDS
            server.  A complete record of trigger changes is kept in the table  <xref linkend="table_trigger_hist" xrefstyle="table"/>, 
            which was discussed in <xref linkend="sync-triggers" />.
        </para>
    </section>
     <section id="resync-data">
        <title>Re-synchronizing Data</title>
        <para>
        There may be times where you find you need to re-send or re-synchronize data when the change itself was not captured.  This could be needed, for example,
        if the data changes occurred prior to SymmetricDS placing triggers on the data tables themselves, or if the data at the destination was accidentally deleted, or for 
        some other reason.  Two approaches are commonly taken to re-send the data, both of which are discussed below.
        </para>
        
      <important>
            <para>Be careful when re-sending data using either of these two techniques.  Be sure you are only sending the rows you intend to send and,
            more importantly, be sure to re-send the data in a way that won't cause foreign key constraint issues at the destination.  In other words,
            if more than one table is involved, be sure to send any tables which are referred to by other tables by foreign keys first.  Otherwise,
            the channel's synchronization will block because SymmetricDS is unable to insert or update the row because the foreign key relationship refers to
            a non-existent row in the destination!
           </para>
      </important>
            
        <para>One possible approach would be to "touch" the rows in individual tables that need re-sent.  By "touch", we mean to alter the row data in such a way
        that SymmetricDS detects a data change and therefore includes the data change in the batching and synchronizing steps.  Note that you have to
        change the data in some meaningful way (e.g., update a time stamp); setting a column to its current value is not sufficient (by default, if there's not an actual data 
        value change SymmetricDS won't treat the change as something which needs synched.
        </para>
        <para>A second approach would be to take advantage of SymmetricDS built-in functionality by simulating a partial "initial load" of the data.  The approach
        is to manually create "reload" events in <xref linkend="table_data" xrefstyle="table"/> for the necessary tables, thereby resending the desired rows for the given tables.  
        Again, foreign key constraints must be kept in mind when creating these reload events.  These reload events are created in the source database itself, and
        the necessary table, trigger-router combination, and channel are included to indicate the direction of synchronization.</para>
        <para>
        To create a reload event, you create a <xref linkend="table_data" xrefstyle="table"/> row, using:
       <itemizedlist>
        <listitem>data_id:  null</listitem>
        <listitem>table_name:  name of table to be sent</listitem>
        <listitem>event_type: 'R', for reload</listitem>
        <listitem>row_data:  a "where" clause (minus the word 'where') which defines the subset of rows from the table to be sent.  To send all rows, one can use 1=1 for this value.</listitem>
        <listitem>pk_data:  null</listitem>
        <listitem>old_data: null</listitem>
        <listitem>trigger_hist_id:  use the id of the most recent entry (i.e., max(trigger_hist_id) ) in <xref linkend="table_trigger_hist" xrefstyle="table"/> 
        for the trigger-router combination for your table and router.</listitem>
        <listitem>channel_id:  the channel in which the table is routed</listitem>
        <listitem>transaction_id:  pick a value, for example '1'</listitem>
        <listitem>source_node_id: null</listitem>
        <listitem>external_data: null</listitem>
        <listitem>create_time:  current_timestamp</listitem>
        </itemizedlist>
        </para>
        
        <para>
        By way of example, take our retail hands-on tutorial covered in <xref linkend="tutorial" />.  Let's say
        we need to re-send a particular sales transaction from the store to corp over again because we lost the data in corp due to
        an overzealous delete.  For the tutorial, all transaction-related tables start with <ns:literal>sale_</ns:literal>, 
        use the <ns:literal>sale_transaction</ns:literal> channel, and are routed using the <ns:literal>store_corp_identity</ns:literal>
        router.  In addition, the trigger-routers have been set up with an initial load order based on the necessary 
        foreign key relationships (i.e., transaction tables which are "parents" have a lower initial load order than those of their
        "children").  An insert statement that would create the necessary "reload" events (three in this case, one for each table) would be as follows
        (where MISSING_ID is changed to the needed transaciton id):
       <programlisting>
       
insert into sym_data (
    select null, t.source_table_name, 'R', 'tran_id=''MISSING-ID''', null, null,
            h.trigger_hist_id, t.channel_id, '1', null, null, current_timestamp
        from sym_trigger t inner join sym_trigger_router tr on
            t.trigger_id=tr.trigger_id inner join sym_trigger_hist h on
            h.trigger_hist_id=(select max(trigger_hist_id) from sym_trigger_hist
                where trigger_id=t.trigger_id) 
    where channel_id='sale_transaction' and
        tr.router_id like 'store_corp_identity' and 
        (t.source_table_name like 'sale_%') 
    order by tr.initial_load_order asc);
    </programlisting>
    
    This insert statement generates three rows, one for each configured sale table.  It uses the most recent
    trigger history id for the corresponding table.  Finally, it takes advantage of the initial load order for each trigger-router to
    create the three rows in the correct order (the order corresponding to the order in which the tables would have been initial loaded).
    
    </para>
    </section>
    <section id="changing-configuration">
        <title>Changing Configuration</title>
        <para>
            The configuration of your system as defined in the <literal>sym_*</literal> tables may be modified at runtime.  By default, any changes made to 
            the <literal>sym_*</literal> tables (with the exception of <literal>sym_node</literal>) should be made at the registration server.  The changes will
            be synchronized out to the leaf nodes by SymmetricDS triggers that are automatically created on the tables.
         </para>
         <para>   
            If this behavior is not desired, the feature can be turned off using a parameter.  Custom triggers may be added
            to the <literal>sym_*</literal> tables when the auto syncing feature is disabled.
        </para>
    </section> 
    
     <section id='logging'>
        <title>Logging Configuration</title>    
        <para>
        The standalone SymmetricDS installation uses <ulink url="http://logging.apache.org/log4j/1.2/index.html">Log4J</ulink> for logging.  The configuration file is  <literal>conf/log4j.xml</literal>.
        The <literal>log4j.xml</literal> file has hints as to what logging can be enabled for useful, finer-grained logging.
        </para>
        <para>
        SymmetricDS proxies all of its logging through <ulink url="http://commons.apache.org/logging/">Commons Logging</ulink>.  When deploying to an application server, if Log4J is not 
        being leveraged, then the general rules for for Commons Logging apply.
        </para>
    </section> 
    
     <section id="admin-jmx">
        <title>Java Management Extensions</title>
        <para>
          Monitoring and administrative operations can be performed using Java Management Extensions (JMX).
          SymmetricDS uses MX4J to expose JMX attributes and operations that can be accessed
          from the built-in web console, Java's jconsole, or an application server.  
          By default, the web management console can be opened from the following address:

          <programlisting><![CDATA[http://localhost:31416/]]></programlisting>

          Using the Java jconsole command, SymmetricDS is listed as a local process named SymmetricLauncher.
          In jconsole, SymmetricDS appears under the MBeans tab under then name defined by the <literal>engine.name</literal>
          property.  The default value is SymmetricDS.
        </para>
        <para>
          The management interfaces under SymmetricDS are organized as follows:

            <itemizedlist>
                <listitem>
                    <para>Node - administrative operations </para>
                </listitem>
                <listitem>
                    <para>Incoming - statistics about incoming batches </para>
                </listitem>
                <listitem>
                    <para>Outgoing - statistics about outgoing batches </para>
                </listitem>
                <listitem>
                    <para>Parameters - access to properties set through the parameter service </para>
                </listitem>
                <listitem>
                    <para>Notifications - setting thresholds and receiving notifications </para>
                </listitem>
            </itemizedlist>
          
        </para>
    </section>
    
    
    
    <section id="temporary-files">
        <title>Temporary Files</title>
        <para>
        SymmetricDS creates temporary extraction and data load files with the CSV payload of a synchronization when
        the value of the <literal>stream.to.file.threshold.bytes</literal> SymmetricDS property has been reached.  Before reaching the threshold, files 
        are streamed to/from memory.  The default threshold value is 32,767 bytes. This feature may be turned off by setting the <literal>stream.to.file.enabled</literal> 
        property to false.
        </para>
        <para>
        SymmetricDS creates these temporary files in the directory specified by the <literal>java.io.tmpdir</literal> Java System property.  When  
        SymmmetricDS starts up, stranded temporary files are aways cleaned up.  Files will only be stranded if the SymmetricDS engine is force killed.
        </para>
        <para>
        The location of the temporary directory may be changed by setting the Java System property passed into the Java program at startup.  For example,
        <programlisting>
  -Djava.io.tmpdir=/home/.symmetricds/tmp
        </programlisting>   
        </para>
    </section>   
    
    
    <section id="purge">
        <title>Database Purging</title>
        <para>
            Purging is the act of cleaning up captured data that is no longer needed in SymmetricDS's runtime tables.  
            Data is purged through
            delete statements by the <emphasis>Purge Job</emphasis>.  Only data that has been successfully synchronized will be purged.  Purged tables include:
            <itemizedlist>
                <listitem>
                   <xref linkend="table_data" xrefstyle="table"/>
                </listitem>
                <listitem>
                    <xref linkend="table_data_event" xrefstyle="table"/>
                </listitem>
                <listitem>
                  <xref linkend="table_outgoing_batch" xrefstyle="table"/>
                </listitem>
                <listitem>
                    <xref linkend="table_incoming_batch" xrefstyle="table"/>
                </listitem>
                <listitem>
                    <xref linkend="table_data_gap" xrefstyle="table"/>
                </listitem>
                <listitem>
                   <xref linkend="table_node_host_stats" xrefstyle="table"/>
                </listitem>     
                <listitem>
                   <xref linkend="table_node_host_channel_stats" xrefstyle="table"/>
                </listitem>  
                <listitem>
                   <xref linkend="table_node_host_job_stats" xrefstyle="table"/>
                </listitem>                   
            </itemizedlist>
            The purge job is enabled by the <literal>start.purge.job</literal> SymmetricDS property.  The job runs periodically according to the 
            <literal>job.purge.period.time.ms</literal> property.  The default period is to run every ten minutes.  
        </para>      
        <para>
            Two retention period properties
            indicate how much history SymmetricDS will retain before purging.  The <literal>purge.retention.minutes</literal> property indicates the period
            of history to keep for synchronization tables.  The default value is 5 days.
            The <literal>statistic.retention.minutes</literal> property
            indicates the period of history to keep for statistics.  The default value is also 5 days.            
        </para>
        <para>
            The purge properties should be adjusted according to how much data is flowing through the system and the amount of storage space the database has.
            For an initial deployment it is recommended that the purge properties be kept at the defaults, since it is often helpful to be able to look at 
            the captured data in order to triage problems and profile the synchronization patterns.  When scaling up to more nodes, it is recomended that the 
            purge parameters be scaled back to 24 hours or less.  
        </para>
    </section>
    
    
 
  
    
</chapter>
