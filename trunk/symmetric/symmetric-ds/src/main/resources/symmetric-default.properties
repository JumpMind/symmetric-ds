#########################################################################
##  Basic Properties
#########################################################################

# The node group id that this node belongs to
group.id=please set me

# The external id for this SymmetricDS node.  The external id is  
# usually used as all or part of the node id.
external.id=please set me

# This is the URL this node will use to register and pull it's configuration.
# If this is the root server, then this may remain blank and the configuration 
# should be inserted directly into the database
registration.url=please set me

# The url that can be used to access this SymmetricDS node.
# The default setting of http://$(hostName):31415/sync should be 
# valid of the standalone launcher is used with the default settings
# The tokens of $(hostName) and $(ipAddress) are supported for this property.
sync.url=http://$(hostName):31415/sync

# Specify your database driver
#db.driver=com.mysql.jdbc.Driver
#db.driver=oracle.jdbc.driver.OracleDriver
#db.driver=org.postgresql.Driver
#db.driver=org.apache.derby.jdbc.EmbeddedDriver
#db.driver=org.hsqldb.jdbcDriver
#db.driver=net.sourceforge.jtds.jdbc.Driver
#db.driver=com.ibm.db2.jcc.DB2Driver
db.driver=org.h2.Driver

# Specify your database URL
#db.url=jdbc:oracle:thin:@127.0.0.1:1521:sampleroot
#db.url=jdbc:postgresql://localhost/sampleroot
#db.url=jdbc:derby:sampleroot;create=true
#db.url=jdbc:hsqldb:file:sampleroot;shutdown=true
#db.url=jdbc:jtds:sqlserver://localhost:2299/sampleroot
#db.url=jdbc:db2://localhost/samproot
#db.url=jdbc:mysql://localhost/sampleroot
db.url=jdbc:h2:sampleroot;AUTO_SERVER=TRUE

# Specify your database user
db.user=

# Specify your database password
db.password=

# The initial size of the connection pool
db.pool.initial.size=5

# The maximum number of connections that will be allocated in the pool
# The http.concurrent.workers.max value should be half or less than half of
# this value.
db.pool.max.active=40

# This is the query to validate the database connection in Connection Pool.
# It is database specific.  The following are example statements for different databases.
# MySQL
#  db.validation.query=select 1
# Oracle
#  db.validation.query=select 1 from dual
# DB2
#  db.validation.query=select max(1) from syscat.datatypes 
db.validation.query=

# This is the number of HTTP concurrent push/pull requests SymmetricDS will accept.  This is controlled
# by the NodeConcurrencyFilter. The number is per servlet the filter is applied to.  The 
# db.pool.max.active value should be twice this value.
#
# This property can be overridden in the database
http.concurrent.workers.max=20

#########################################################################
##  Advanced Properties
#########################################################################

# When symmetric tables are created and accessed, this is the prefix to use for the tables.
sync.table.prefix=sym

# If this is true, when symmetric starts up it will try to create the necessary tables
auto.config.database=true

# If this is true. when symmetric starts up it will make sure the triggers in the database are up to date
auto.sync.triggers=true

# If this is true, when symmetric starts up it will try to upgrade tables to latest version
auto.upgrade=true

# Send symmetricds changes to client nodes when configuration changes
auto.sync.configuration=true

# This is how long the default transaction time is.
# This needs to be fairly big to account for large data loads.   
db.tx.timeout.seconds=7200

# Most symmetric queries have a timeout associated with them.  This is the default.
db.sql.query.timeout.seconds=300

# Set the name of the spring bean that is the DataSource to use.  This property maybe be overridden so the end user can specify 
# their own DataSource
db.spring.bean.name=symmetricBasicDataSource

# Name of class that can extract native JDBC objects and interact directly with the driver.
# Spring uses this to perform operations specific to database, like handling LOBs on Oracle.
db.native.extractor=org.springframework.jdbc.support.nativejdbc.CommonsDbcpNativeJdbcExtractor

# Set the JNDI name if symmetric should use a JNDI registered connection pool# It is recommended that the application server provided Datasource is NOT transactional.  
# Symmetric will handle transactionality.  
# If NOT using a JNDI connection pool, provide information about the database connection. 
# A DBCP connection pool will be created.
db.jndi.name=

# This is how long a request for a connection from the datasource will wait before
# giving up.
db.pool.max.wait.millis=30000

# This is how long a connection can be idle before it will be evicted.
db.pool.min.evictable.idle.millis=120000

# This is the default fetch size for streaming result sets.                
db.jdbc.streaming.results.fetch.size=1000

# This is the schema that will be used for metadata lookup. Some dialect automatically
# figure this out using database specific SQL to get the current schema
db.default.schema=

# Use to map the version string a zseries jdbc driver returns to the 'zseries' dialect
db2.zseries.version=DSN08015

# Indicates that case should be ignored when looking up references to tables using the metadata api.
db.metadata.ignore.case=true

# Update the node row in the database from the local properties during a heartbeat operation
auto.update.node.values.from.properties=true

# This is the engine name.  This should be set if you have more than one engine running in the same JVM.
# It is used to name the JMX management bean.  Please do not use underscores in this name.
engine.name=SymmetricDS

# Set this if you want to give your server a unique name to be used to identify which server did what action.  Typically useful when running in 
# a clustered environment.  This is currently used by the ClusterService when locking for a node.
cluster.server.id=

# This is hook to give the user a mechanism to indicate the schema version that is being synchronized.
#
# This property can be overridden in the database                       
schema.version=?

# This is the number of times registration will be attempted before being aborted.  The default
# value is -1 which means an endless number of attempts.
registration.number.of.attempts=-1

# Set this if tables should be purged prior to an initial load
#
# This property can be overridden in the database
initial.load.delete.first=false

# Save data to the file system before transporting it to the client or loading
# it to the database if the number of bytes is past a certain threshold.  This allows
# for better compression and better use of database and network resources.  Statistics
# in the batch tables will be more accurate if this is set to true because each timed
# operation is independent of the others.
#
# This property can be overridden in the database
stream.to.file.enabled=true

# If stream.to.file.enabled is true, then the threshold number of bytes at which a file 
# will be written is controlled by this property.  Note that for a synchronization the
# entire payload of the synchronization will be buffered in memory up to this number (at
# which point it will be written and continue to stream to disk)
#
# This property can be overridden in the database
stream.to.file.threshold.bytes=32767

# Set this if tables should be created prior to an initial load
#
# This property can be overridden in the database
initial.load.create.first=false

# If this is true, registration is opened automatically for nodes requesting it
#
# This property can be overridden in the database
auto.registration=false

# If this is true, a reload is automatically sent to nodes when they register
#
# This property can be overridden in the database
auto.reload=false

# If this is true, then node, group, security and identity rows will be inserted if the 
# registration.url is blank and there is no configured node identity.
auto.insert.registration.svr.if.not.found=false

# Provide the path to a SQL script that can be run to do initial setup of a registration server.  This script
# will only be run on a registration server if the node_identity cannot be found.
auto.config.registration.svr.sql.script=

# This is the download rate for the HTTP symmetric transport.  -1 means full throttle.
http.download.rate.kb=-1

# This is the amount of time the host will keep a concurrent connection reservation after it has
# been attained by a client node while waiting for the subsequent reconnect to push
http.concurrent.reservation.timeout.ms=20000

# During SSL handshaking, if the URL's hostname and the server's 
# identification hostname mismatch, the verification mechanism 
# will check this comma separated list of server names to see if the 
# cert should be accepted (see javax.net.ssl.HostnameVerifier)
https.verified.server.names=

# This is the maximum number of events that will be peeked at to look for additional transaction rows after
# the max batch size is reached.  The more concurrency in your db and the longer the transaction takes the 
# bigger this value might have to be.
#
# This property can be overridden in the database 
routing.peek.ahead.window.after.max.size=1000

# This is the time that any gaps in data_ids will be considered stale and skipped.
#
# This property can be overridden in the database 
routing.stale.dataid.gap.time.ms=7200000

# This is the type of algorithm that will be used by SymmetricDS to select captured data for routing.
# The two possible values are ref and gap.
routing.data.reader.type=ref

routing.data.reader.type.gap.retention.period.minutes=1440

# This is the number of datae vents that will be batched and committed together while building a batch.
# Note that this only kicks in if the prospective batch size is bigger than the configured max batch size.
#
# This property can be overridden in the database 
outgoing.batches.peek.ahead.batch.commit.size=10
                             
# This instructs symmetric to attempt to skip duplicate batches that are received.  Symmetric might
# be more efficient when recovering from error conditions if this is set to true, but you run the
# risk of missing data if the batch ids get reset (on one node, but not another) somehow (which is unlikely in production, but
# fairly likely in lab or development setups). 
#
# This property can be overridden in the database
incoming.batches.skip.duplicates=true

# If this property is set to true, then keys will not be included in set portion of
# the update statements generated by the data loader.
#
# This property can be overridden in the database
dont.include.keys.in.update.statement=false

# Disable the loading of all channel with the exception of the config channel.  This
# property can be set to allow all changes to be extracted without introducing other 
# changes in order to allow maintenance operations.
#
# This property can be overridden in the database
dataloader.enable=true

# Disable the extraction of all channels with the exception of the config channel
#
# This property can be overridden in the database
dataextractor.enable=true

# Disable the extraction of old data
#
# This property can be overridden in the database
dataextractor.old.data.enable=true

# Turn on/off fallback to update statements after an integrity 
# error on an insert
#
# This property can be overridden in the database
dataloader.enable.fallback.update=true

# For dialects that roll back on integrity errors, enabled the use of savepoints 
# before inserts, otherwise it will try to select the row by primary key.
#
# This property can be overridden in the database
dataloader.enable.fallback.savepoint=true

# Turn on/off fallback to insert statements after a failed
# update
#
# This property can be overridden in the database
dataloader.enable.fallback.insert=true

# Do not fail a load if a delete did not delete anything.
#
# This property can be overridden in the database
dataloader.allow.missing.delete=true

# This is the maximum number of rows that will be supported in a 
# single transaction.  If the database transaction row count reaches a size 
# that is greater than this number then the transaction will be auto committed.
# The default value of -1 indicates that there is no size limit.
#
# This property can be overridden in the database
dataloader.max.rows.before.commit=-1

# This is the number of times we will attempt to send an ACK back to the remote node
# when pulling and loading data.
#
# This property can be overridden in the database
num.of.ack.retries=5

# This is the amount of time to wait between trying to send an ACK back to the remote node
# when pulling and loading data.
#
# This property can be overridden in the database
time.between.ack.retries.ms=5000

# The number of milliseconds parameters will be cached by the ParameterService before they are reread from the 
# file system and database.
#
# This property can be overridden in the database
parameter.reload.timeout.ms=600000

# This is the amount of time node security entries will be cached before rereading
# them from the database.
#
# This property can be overridden in the database
cache.node.security.time.ms=0

# This is the amount of time trigger entries will be cached before rereading them from the database.
#
# This property can be overridden in the database
cache.trigger.router.time.ms=600000

# This is the amount of time channel entries will be cached before rereading them from the database.
#
# This property can be overridden in the database
cache.channel.time.ms=60000

# Indicate that this node is being run on a farm or cluster of servers and it needs to use the database to 'lock' out other activity when actions are taken.
cluster.lock.timeout.ms=1800000

# Enables clustering of jobs
#
# This property can be overridden in the database
cluster.lock.enabled=false

# Sets both the connection and read timeout on the internal HttpUrlConnection
#
# This property can be overridden in the database
http.timeout.ms=900000

# Whether or not to use compression over HTTP connections.
# Currently, this setting only affects the push connection of the source node.
# Compression on a pull is enabled using a filter in the web.xml for the PullServlet.
# @see web.compression.disabled to enable/disable the filter
#
# This property can be overridden in the database
http.compression=true

# The HTTP client connection, during a push, buffers the entire outgoing pay-load locally
# before sending it.  Set this to true if you are getting heap space errors during
# a push.  Note that basic auth may not work when this is turned on.
#
# This property can be overridden in the database
http.push.stream.output.enabled=false

# When HTTP chunking is turned on, this is the size to use for each chunk.
#
# This property can be overridden in the database
http.push.stream.output.size=30720

# Disable compression from occurring on Servlet communication.  This property only
# affects the outbound HTTP traffic streamed by the PullServlet and PushServlet.
#
# This property can be overridden in the database
web.compression.disabled=false

# Set the compression level this node will use when compressing synchronization payloads
# @see java.util.zip.Deflater
# NO_COMPRESSION = 0
# BEST_SPEED = 1
# BEST_COMPRESSION = 9
# DEFAULT_COMPRESSION = -1
#
# This property can be overridden in the database
compression.level=-1

# Set the compression strategy this node will use when compressing synchronization payloads
# @see java.util.zip.Deflater
# FILTERED = 1
# HUFFMAN_ONLY = 2
# DEFAULT_STRATEGY = 0
#
# This property can be overridden in the database
compression.strategy=0

# The base servlet path for when embedding SymmetricDS with another web application
web.base.servlet.path=

# Indicate whether the batch servlet (which allows specific batches to be requested) is enabled.
web.batch.servlet.enable=true

# When starting jobs, symmetric attempts to randomize the start time to spread out load.  This is the
# maximum wait period before starting a job.
job.random.max.start.time.ms=10000

# This is the retention for how long synchronization data will be kept in the symmetric synchronization
# tables.  Note that data will be purged only if the purge job is enabled.
purge.retention.minutes=7200

statistic.retention.minutes=7200

# This is how often the push job will be run.
job.push.period.time.ms=60000

# This is how often the pull job will be run.
job.pull.period.time.ms=60000

# This is how often accumulated statistics will be flushed out to the database from memory
job.stat.flush.period.time.ms=600000

# This is how often the router will run in the background
job.routing.period.time.ms=10000

# This is how often the heartbeat job runs.  Not that this doesn't mean that a heartbeat 
# is performed this often.  
# see heartbeat.sync.on.push.period.sec to change how often the heartbeat is sync'd
job.heartbeat.period.time.ms=1000

job.watchdog.period.time.ms=3600000

# This is how often the purge job will be run
job.purge.cron=0 0 0 * * *

# This is when the sync triggers job will run
job.synctriggers.cron=0 0 0 * * *

# This is the number of data events by batch that will be purged in one database transaction
job.purge.max.num.data.events.to.delete.in.tx=100

# This is the number of batches that will be purged in one database transaction
job.purge.max.num.batches.to.delete.in.tx=5000

# This is the number of data ids that will be purged in one database transaction
job.purge.max.num.data.to.delete.in.tx=5000

# Whether the batch job is enabled for this node.                                                              
start.route.job=true

# Whether the pull job is enabled for this node.                                                              
start.pull.job=true

# Whether the push job is enabled for this node.   
start.push.job=true

# Whether the purge job is enabled for this node.
start.purge.job=true

# Whether the heartbeat job is enabled for this node.  The heartbeat job simply
# inserts an event to update the heartbeat_time column on the node table for the current node.
start.heartbeat.job=true

# Whether the sync triggers job is enabled for this node. 
start.synctriggers.job=true

# Whether the statistic flush job is enabled for this node.
start.stat.flush.job=true

# Whether the watchdog job is enabled for this node.
start.watchdog.job=true

# Specify the transport type.  Supported values currently include: http, internal
transport.type=http

# If using the HsqlDbDialect, this property indicates whether Symmetric should setup the embedded database properties or if an
# external application will be doing so.
hsqldb.initialize.db=true

# This is the precision that is used in the number template for oracle triggers
oracle.template.precision=30,10

# Requires access to gv$transaction
oracle.use.transaction.view=false

# Specify the type of line feed to use in JMX console methods.  Possible values are: text or html.
jmx.line.feed=text

# Specify whether the legacy JMX interfaces should be enabled or not.
jmx.legacy.beans.enabled=false

jmx.http.console.for.embedded.webserver.enabled=true

jmx.http.console.localhost.only.enabled=false

# Specify whether we should publish alerts if any of the statistic flushes fall outside a specified
# threshold range.
statistic.threshold.alerts.enabled=false

ip.filters=*.*.*.*

# Specify whether to push node records to configured push clients.  If this is true
# the node for this instance and the node rows for all children instances will be pushed
# to all nodes that this node is configured to push to.
heartbeat.sync.on.push=true

# This is the number of seconds between when the heartbeat job runs.
heartbeat.sync.on.push.period.sec=900

# This is the number of minutes that a node has been offline before taking action
# A value of -1 (or any negative value) disables the feature.
offline.node.detection.period.minutes=-1

# Enabled this property to force a compare of old and new data in triggers.  If
# old=new, then don't record the change.
#
# This is currently supported by the following dialects:  mysql
trigger.update.capture.changed.data.only.enabled=false