<?xml version="1.0" encoding="UTF-8"?>
<!--

    Licensed to JumpMind Inc under one or more contributor
    license agreements.  See the NOTICE file distributed
    with this work for additional information regarding
    copyright ownership.  JumpMind Inc licenses this file
    to you under the GNU General Public License, version 3.0 (GPLv3)
    (the "License"); you may not use this file except in compliance
    with the License.

    You should have received a copy of the GNU General Public License,
    version 3.0 (GPLv3) along with this library; if not, see
    <http://www.gnu.org/licenses/>.

    Unless required by applicable law or agreed to in writing,
    software distributed under the License is distributed on an
    "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
    KIND, either express or implied.  See the License for the
    specific language governing permissions and limitations
    under the License.

-->
<chapter version="5.0" xml:id="config"
	xmlns="http://docbook.org/ns/docbook"
	xmlns:xlink="http://www.w3.org/1999/xlink"
	xmlns:xi="http://www.w3.org/2001/XInclude"
	xmlns:svg="http://www.w3.org/2000/svg"
	xmlns:ns="http://docbook.org/ns/docbook"
	xmlns:mml="http://www.w3.org/1998/Math/MathML"
	xmlns:html="http://www.w3.org/1999/xhtml">
	
	<title>Configuration</title>
	
	<section id="configuration-groups">
		<title>Groups</title>
		<para>
		Groups are defined in the
		<xref linkend="table_node_group" xrefstyle="table" />
		table. The following SQL statements would create node groups for "corp"
		and "store" based on our retail store example.
		<programlisting> 
        insert into SYM_NODE_GROUP
		  (node_group_id, description) 
          values ('store', 'A retail store node');
		
		insert into SYM_NODE_GROUP 
          (node_group_id, description) 
          values ('corp', 'A corporate node');</programlisting>
		</para>
	</section>
	<section id="configuration-group-links">
		<title>Group Links</title>
		<para>
		Group links are defined in the
		<xref linkend="table_node_group_link" xrefstyle="table" />
		table.  Links define how a node that belongs to a group will communicate with nodes in other groups.
        The following are the communication mechanisms that can be configured.
        
        <variablelist>
        <varlistentry>
        <term>
        <command>Push (P)</command>
        </term>        
        <listitem>
        <para>Indicates that the source node will initiate communication over an HTTP PUT.</para>
        </listitem>
        </varlistentry>
        
        <varlistentry>
        <term>
        <command>Wait for Pull (W)</command>
        </term>        
        <listitem>
        <para>Indicates that the source node will <ns:emphasis>wait</ns:emphasis> for a target node to connect via an HTTP GET to pull data.</para>
        </listitem>
        </varlistentry>
        
        <varlistentry>
        <term>
        <command>Route-only (R)</command>
        </term>        
        <listitem>
        <para>Route-only indicates that the data isn't going to be transported via SymmetricDS.  This action type might be useful when using an XML publishing
        router or an audit table changes router.</para>
        </listitem>
        </varlistentry>
        </variablelist> 
        </para>
        
        <para>The link also defines if configuration data will be synchronized on the link.  For example, you might not want remote nodes to be able to change
        configuration and effect other nodes in the network.  In this case you would set <ns:literal>sync_config_enabled</ns:literal> to 0 on the appropriate link.</para>
        
        <para>A link can be configured to use the same node
        group as the source and the target. This configuration allows a node
        group to sync with every other node in its group.</para>
        
        <para>
        The following SQL statements
		links the "corp" and "store" node groups for synchronization. It
		configures the "store" nodes to push their data changes to the "corp"
		nodes, and the "corp" nodes to send changes to "store" nodes by waiting
		for a pull.
		<programlisting> 
        insert into SYM_NODE_GROUP_LINK
		  (source_node_group, target_node_group, data_event_action) 
          values ('store', 'corp', 'P');
           
        insert into SYM_NODE_GROUP_LINK
		  (source_node_group, target_node_group, data_event_action) 
          values ('corp', 'store', 'W');</programlisting>
		</para>		
	</section>
	<section id="configuration-channels">
		<title>Channels</title>
		<para>
		By categorizing data into channels and assigning them to
		<xref linkend="table_trigger" xrefstyle="table" />
		s, the user gains more control and visibility into the flow of data. In
		addition, SymmetricDS allows for synchronization to be enabled,
		suspended, or scheduled by channels as well. The frequency of
		synchronization and order that data gets synchronized is also controlled
		at the channel level.
		</para>
		
		<para>
		The following SQL statements setup channels for a retail store. An
		"item" channel includes data for items and their prices, while a
		"sale_transaction" channel includes data for ringing sales at a
		register.
		<programlisting> 
        insert into SYM_CHANNEL (channel_id, rocessing_order, max_batch_size, max_batch_to_send,
		  extract_period_millis, batch_algorithm, enabled, description) 
          values ('item', 10, 1000, 10, 0, 'default', 1, 'Item and pricing data'); 
        
        insert into SYM_CHANNEL (channel_id, processing_order, max_batch_size,
		  max_batch_to_send, extract_period_millis, batch_algorithm, enabled, description) 
          values ('sale_transaction', 1, 1000, 10, 60000,
		  'transactional', 1, 'retail sale transactions from register');</programlisting>
		</para>
		
		<para>
		Batching is the grouping of data, by channel, to be transferred and
		committed at the client together. There are three different
		out-of-the-box batching algorithms which may be configured in the
		batch_algorithm column on channel.
		<variablelist>
		<varlistentry>
		<term>
		<command>default</command>
		</term>
		
		<listitem>
		<para>All changes that happen in a transaction are guaranteed to
		be batched together. Multiple transactions will be batched and committed
		together until there is no more data to be sent or the max_batch_size is
		reached.</para>
		</listitem>
		</varlistentry>
		
		<varlistentry>
		<term>
		<command>transactional</command>
		</term>
		
		<listitem>
		<para>Batches will map directly to database transactions. If
		there are many small database transactions, then there will be many
		batches. The max_batch_size column has no effect.</para>
		</listitem>
		</varlistentry>
		
		<varlistentry>
		<term>
		<command>nontransactional</command>
		</term>
		
		<listitem>
		<para>Multiple transactions will be batched and committed
		together until there is no more data to be sent or the max_batch_size is
		reached. The batch will be cut off at the max_batch_size regardless of
		whether it is in the middle of a transaction.</para>
		</listitem>
		</varlistentry>
		</variablelist>
		</para>
		
		<para>
		If a channel contains
		<emphasis>only</emphasis>
		tables that will be synchronized in one direction and and data is routed
		to all the nodes in the target node groups, then batching on the channel
		can be optimized to share batches across nodes. This is an important
		feature when data needs to be routed to thousands of nodes. When this
		mode is detected, you will see batches created in
		<xref linkend="table_outgoing_batch" xrefstyle="table" />
		with the
		<literal>common_flag</literal>
		set to 1.
		</para>
		
		<para>
		There are also several size-related parameters that can be set by
		channel. They include:
		<variablelist>
		<varlistentry>
		<term>
		<command>max_batch_size</command>
		</term>
		
		<listitem>
		<para>Specifies the maximum number of data events to process
		within a batch for this channel.</para>
		</listitem>
		</varlistentry>
		
		<varlistentry>
		<term>
		<command>max_batch_to_send</command>
		</term>
		
		<listitem>
		<para>Specifies the maximum number of batches to send for a given
		channel during a 'synchronization' between two nodes. A
		'synchronization' is equivalent to a push or a pull. For example, if
		there are 12 batches ready to be sent for a channel and
		max_batch_to_send is equal to 10, then only the first 10 batches will be
		sent even though 12 batches are ready.</para>
		</listitem>
		</varlistentry>
		
		<varlistentry>
		<term>
		<command>max_data_to_route</command>
		</term>
		
		<listitem>
		<para>Specifies the maximum number of data rows to route for a
		channel at a time.</para>
		</listitem>
		</varlistentry>
		</variablelist>
		</para>
		
		<para>Based on your particular synchronization requirements, you
		can also specify whether old, new, and primary key data should be read
		and included during routing for a given channel. These are controlled by
		the columns use_old_data_to_route, use_row_data_to_route, and
		use_pk_data_to_route, respectively. By default, they are all 1 (true).</para>
		
		<para>
		If data on a particular channel contains big lobs, you can set
		the column contains_big_lob to 1 (true) to provide SymmetricDS the hint
		that the channel contains big lobs. Some databases have shortcuts that
		SymmetricDS can take advantage of if it knows that the lob columns in
		<xref linkend="table_data" xrefstyle="table" />
		aren't going to contain large lobs. The definition of how large a 'big'
		lob is varies from database to database.
		</para>
	</section>
	<section id="configuration-table-triggers">
	<title>Table Triggers</title>
	
		<para>
		SymmetricDS captures synchronization data using database triggers.
		SymmetricDS' Triggers are defined in the
		<xref linkend="table_trigger" xrefstyle="table" />
		table. Each record is used by SymmetricDS when generating database
		triggers. Database triggers are only generated when a trigger is
		associated with a
		<xref linkend="table_router" xrefstyle="table" />
		whose
		<literal>source_node_group_id</literal>
		matches the node group id of the current node.
		</para>
		
		<para>
		The
		<literal>source_table_name</literal>
		may contain the asterisk ('*') wildcard character so that one
		<xref linkend="table_trigger" xrefstyle="table" />
		table entry can define synchronization for many tables. System tables
		and any tables that start with the SymmetricDS table prefix will be
		excluded. A list of wildcard tokens can also be supplied. If there are
		multiple tokens, they should be delimited with a comma. A wildcard token
		can also start with a bang ('!') to indicate an exclusive match. Tokens
		are always evalulated from left to right. When a table match is made,
		the table is either added to or removed from the list of tables. If
		another trigger already exists for a table, then that table is not
		included in the wildcard match (the explictly defined trigger entry take
		precendence).
		</para>
		
		<para>
		When determining whether a data change has occurred or not, by defalt
		the triggers will record a change even if the data was updated to the
		same value(s) they were originally. For example, a data change will be
		captured if an update of one column in a row updated the value to the
		same value it already was. There is a global property,
		<literal>trigger.update.capture.changed.data.only.enabled</literal>
		(false by default), that allows you to override this behavior. When set
		to true, SymmetricDS will only capture a change if the data has truly
		changed (i.e., when the new column data is not equal to the old column
		data).
		</para>
		
		<important>
		The property
		<literal>trigger.update.capture.changed.data.only.enabled</literal>
		is currently only supported in the MySQL, DB2, SQL Server and Oracle dialects.
		</important>
		
		<para>
		The following SQL statement defines a trigger that will capture data for
		a table named "item" whenever data is inserted, updated, or deleted. The
		trigger is assigned to a channel also called 'item'.
		<programlisting> 
        insert into SYM_TRIGGER (trigger_id, source_table_name,
          channel_id, last_update_time, create_time)
		  values ('item', 'item', 'item', current_timestamp, current_timestamp); </programlisting>
		</para>
		
		<important>
		<para>Note that many databases allow for multiple triggers of the
		same type to be defined. Each database defines the order in which the
		triggers fire differently. If you have additional triggers beyond those
		SymmetricDS installs on your table, please consult your database
		documentation to determine if there will be issues with the ordering of
		the triggers.</para>
		</important>
		<section id="configuration-trigger-router">
			<title>Linking Triggers</title>

			<para>
			The
			<xref linkend="table_trigger_router" xrefstyle="table" />
			table is used to define which specific combinations of triggers and
			routers are needed for your configuration. The relationship between
			triggers and routers is many-to-many, so this table serves as the join
			table to define which combinations are valid, as well as to define
			settings available at the trigger-router level of granularity.
			</para>
			<para>
			Three important controls can be configured for a specific Trigger /
			Router combination: Enabled, Initial Loads and Ping Back. The parameters
			for these can be found in the Trigger / Router mapping table,
			<xref linkend="table_trigger_router" xrefstyle="table" />
			.
			</para>
			
			<section id="configuration-trigger-router-enabled">
				<title>Enable / disable trigger router</title>
				
				<para>
				Each individual trigger-router combination can be disabled or enabled if
				needed. By default, a trigger router is enabled, but if you have a
				reason you wish to define a trigger router combination prior to it being
				active, you can set the
				<literal>enabled</literal>
				flag to 0. This will cause the trigger-router mapping to be sent to all
				nodes, but the trigger-router mapping will not be considered active or
				enabled for the purposes of capturing data changes or routing.
				</para>
			</section>
			<section id="configuration-trigger-router-ping-back">
				<title>Enabling "Ping Back"</title>
				
				<para>
				SymmetricDS, by default, avoids circular data changes. When a trigger
				fires as a result of SymmetricDS itself (such as the case when sync on
				incoming batch is set), it records the originating source node of the
				data change in
				<literal>source_node_id</literal>
				. During routing, if routing results in sending the data back to the
				originating source node, the data is not routed by default. If instead
				you wish to route the data back to the originating node, you can set the
				<literal>ping_back_enabled</literal>
				column for the needed particular trigger / router combination. This will
				cause the router to "ping" the data back to the originating node when it
				usually would not.
				</para>
			</section>
		</section>
		<section id="configuration-trigger-lobs">
			<title>Large Objects</title>
			<para>
			Two lobs-related settings are also available on
			<xref linkend="table_trigger" xrefstyle="table" />
			:
			<variablelist>
			<varlistentry>
			<term>
			<command>use_stream_lobs</command>
			</term>
			
			<listitem>
			<para>Specifies whether to capture lob data as the trigger is
			firing or to stream lob columns from the source tables using callbacks
			during extraction. A value of 1 indicates to stream from the source via
			callback; a value of 0, lob data is captured by the trigger.</para>
			</listitem>
			</varlistentry>
			
			<varlistentry>
			<term>
			<command>use_capture_lobs</command>
			</term>
			
			<listitem>
			<para>Provides a hint as to whether this trigger will capture big
			lobs data. If set to 1 every effort will be made during data capture in
			trigger and during data selection for initial load to use lob facilities
			to extract and store data in the database.</para>
			</listitem>
			</varlistentry>
			</variablelist>
			</para>
		</section>
		
		<section id="configuration-trigger-external-select">
			<title>External Select</title>
			
			<para>
			Occasionally, you may find that you need to capture and save away a
			piece of data present in another table when a trigger is firing. This
			data is typically needed for the purposes of determining where to
			'route' the data to once routing takes place. Each trigger definition
			contains an optional
			<literal>external_select</literal>
			field which can be used to specify the data to be captured. Once
			captured, this data is available during routing in
			<xref linkend="table_data" xrefstyle="table" />
			's
			<literal>external_data</literal>
			field. For these cases, place a SQL select statement which returns the
			data item you need for routing in
			<literal>external_select</literal>
			. An example of the use of external select can be found in
			<xref linkend="configuration-routing-external-select" />
			.
			</para>
		</section>
		<section id="configuration-dead-triggers">
			<title>Dead Triggers</title>
			
			<para>
			Occasionally the decision of what data to load initially results in
			additional triggers. These triggers, known as
			<emphasis>Dead Triggers</emphasis>
			, are configured such that they do not capture any data changes. A
			"dead" Trigger is one that does not capture data changes. In other
			words, the
			<literal>sync_on_insert</literal>
			,
			<literal>sync_on_update</literal>
			, and
			<literal>sync_on_delete</literal>
			properties for the Trigger are all set to false. However, since the
			Trigger is specified, it
			<emphasis>will</emphasis>
			be included in the initial load of data for target Nodes.
			</para>
			
			<para>Why might you need a Dead Trigger? A dead Trigger might be
			used to load a read-only lookup table, for example. It could also be
			used to load a table that needs populated with example or default data.
			Another use is a recovery load of data for tables that have a single
			direction of synchronization. For example, a retail store records sales
			transactions that synchronize in one direction by trickling back to the
			central office. If the retail store needs to recover all the sales
			transactions from the central office, they can be sent are part of an
			initial load from the central office by setting up dead Triggers that
			"sync" in that direction.</para>
			
			<para>
			The following SQL statement sets up a non-syncing dead Trigger that
			sends the
			<literal>sale_transaction</literal>
			table to the "store" Node Group from the "corp" Node Group during an
			initial load.
			<programlisting><![CDATA[ 
            insert into sym_trigger (TRIGGER_ID,SOURCE_CATALOG_NAME,
			  SOURCE_SCHEMA_NAME,SOURCE_TABLE_NAME,CHANNEL_ID,
			  SYNC_ON_UPDATE,SYNC_ON_INSERT,SYNC_ON_DELETE,
			  SYNC_ON_INCOMING_BATCH,NAME_FOR_UPDATE_TRIGGER,
			  NAME_FOR_INSERT_TRIGGER,NAME_FOR_DELETE_TRIGGER,
			  SYNC_ON_UPDATE_CONDITION,SYNC_ON_INSERT_CONDITION,
			  SYNC_ON_DELETE_CONDITION,EXTERNAL_SELECT,
			  TX_ID_EXPRESSION,EXCLUDED_COLUMN_NAMES,
			  CREATE_TIME,LAST_UPDATE_BY,LAST_UPDATE_TIME) 
              values ('SALE_TRANSACTION_DEAD',null,null, 'SALE_TRANSACTION','transaction',
			  0,0,0,0,null,null,null,null,null,null,null,null,null,
			  current_timestamp,'demo',current_timestamp); 
              
            insert into sym_router (ROUTER_ID,TARGET_CATALOG_NAME,TARGET_SCHEMA_NAME,
			  TARGET_TABLE_NAME,SOURCE_NODE_GROUP_ID,TARGET_NODE_GROUP_ID,ROUTER_TYPE,
			  ROUTER_EXPRESSION,SYNC_ON_UPDATE,SYNC_ON_INSERT,SYNC_ON_DELETE,
			  CREATE_TIME,LAST_UPDATE_BY,LAST_UPDATE_TIME) 
              values ('CORP_2_STORE',null,null,null, 'corp','store',null,null,1,1,1,
			  current_timestamp,'demo',current_timestamp); 
              
            insert into sym_trigger_router (TRIGGER_ID,ROUTER_ID,INITIAL_LOAD_ORDER,
			  INITIAL_LOAD_SELECT,CREATE_TIME,LAST_UPDATE_BY,LAST_UPDATE_TIME) 
              values ('SALE_TRANSACTION_DEAD','CORP_2_REGION',100,null,
			  current_timestamp,'demo',current_timestamp); ]]></programlisting>
			</para>
		</section>
		<section id="changing-triggers">
	        <title>Changing Triggers</title>
	        <para>
	            A trigger row may be updated using SQL to change a synchronization definition.
	            SymmetricDS will look for changes each night or whenever the Sync Triggers Job
	            is run (see below).  For example, a change to place the table <literal>price_changes</literal>
	            into the price channel would be accomplished with the following statement:
	            <programlisting>
	<![CDATA[
    update SYM_TRIGGER
	  set channel_id = 'price',
	    last_update_by = 'jsmith',
	    last_update_time = current_timestamp
	  where source_table_name = 'price_changes';
	]]></programlisting>
	            All configuration changes should be managed centrally at the registration node.  If enabled, configuration
	            changes will be synchronized out to client nodes.  When trigger changes reach the client
	            nodes the Sync Triggers Job will run automatically.
	         </para>
	         <para>
	            Centrally, the trigger changes will not take effect until the Sync Triggers Job runs.
	            Instead of waiting for the Sync Triggers Job to run overnight after making a Trigger
	            change, you can invoke the syncTriggers() method over JMX or simply restart the SymmetricDS
	            server.  A complete record of trigger changes is kept in the table  <xref linkend="table_trigger_hist" xrefstyle="table"/>,
	            which was discussed in <xref linkend="sync-triggers" />.
	        </para>
	    </section>
	</section>
    <xi:include href="file-sync.xml" />
	<section id="configuration-routers">
	<title>Routers</title>
		<para>
		Routers provided in the base implementation currently include:
		<itemizedlist>
		<listitem>Default Router - a router that sends all data to
		all nodes that belong to the target node group defined in the router.</listitem>
		
		<listitem>Column Match Router - a router that compares old or
		new column values to a constant value or the value of a node's
		external_id or node_id.</listitem>
		
		<listitem>Lookup Router - a router which can be configured to
		determine routing based on an existing or ancillary table specifically
		for the purpose of routing data.</listitem>
		
		<listitem>Subselect Router - a router that executes a SQL
		expression against the database to select nodes to route to. This SQL
		expression can be passed values of old and new column values.</listitem>
		
		<listitem>Scripted Router - a router that executes a Bean
		Shell script expression in order to select nodes to route to. The script
		can use the old and new column values.</listitem>
		
		<listitem>Xml Publishing Router - a router the publishes data
		changes directly to a messaging solution instead of transmitting changes
		to registered nodes. This router must be configured manually in XML as
		an extension point.</listitem>
		
		<listitem>Audit Table Router - a router that inserts into an
		automatically created audit table. It records captured changes to tables
		that it is linked to. </listitem>
		</itemizedlist>
		The mapping between the set of triggers and set of routers is
		many-to-many. This means that one trigger can capture changes and route
		to multiple locations. It also means that one router can be defined an
		associated with many different triggers.
		</para>
		
		<section id="configuration-default-router">
		<title>Default Router</title>
		
		<para>
		The simplest router is a router that sends all the data that is captured
		by its associated triggers to all the nodes that belong to the target
		node group defined in the router. A router is defined as a row in the
		<xref linkend="table_router" xrefstyle="table" />
		table. It is then linked to triggers in the
		<xref linkend="table_trigger_router" xrefstyle="table" />
		table.
		</para>
		
		<para>
		The following SQL statement defines a router that will send data from
		the 'corp' group to the 'store' group.
		<programlisting> insert into SYM_ROUTER (router_id,
		source_node_group_id, target_node_group_id, create_time,
		last_update_time) values ('corp-2-store','corp', 'store',
		current_timestamp, current_timestamp); </programlisting>
		</para>
		
		<para>
		The following SQL statement maps the 'corp-2-store' router to the item
		trigger.
		<programlisting> insert into SYM_TRIGGER_ROUTER
		(trigger_id, router_id, initial_load_order, create_time,
		last_update_time) values ('item', 'corp-2-store', 1, current_timestamp,
		current_timestamp); </programlisting>
		</para>
		</section>
		
		<section id="configuration-column-match-router">
		<title>Column Match Router</title>
		
		<para>
		Sometimes requirements may exist that require data to be routed based on
		the current value or the old value of a column in the table that is
		being routed. Column routers are configured by setting the
		<literal>router_type</literal>
		column on the
		<xref linkend="table_router" xrefstyle="table" />
		table to
		<literal>column</literal>
		and setting the
		<literal>router_expression</literal>
		column to an equality expression that represents the expected value of
		the column.
		</para>
		
		<para>The first part of the expression is always the column name.
		The column name should always be defined in upper case. The upper case
		column name prefixed by OLD_ can be used for a comparison being done
		with the old column data value.</para>
		
		<para>The second part of the expression can be a constant value,
		a token that represents another column, or a token that represents some
		other SymmetricDS concept. Token values always begin with a colon (:).</para>
		
		<para>
		Consider a table that needs to be routed to all nodes in the target
		group only when a status column is set to 'READY TO SEND.' The following
		SQL statement will insert a column router to accomplish that.
		<programlisting> insert into SYM_ROUTER (router_id,
		source_node_group_id, target_node_group_id, router_type,
		router_expression, create_time, last_update_time) values
		('corp-2-store-ok','corp', 'store', 'column', 'STATUS=READY TO SEND',
		current_timestamp, current_timestamp); </programlisting>
		</para>
		
		<para>
		Consider a table that needs to be routed to all nodes in the target
		group only when a status column changes values. The following SQL
		statement will insert a column router to accomplish that. Note the use
		of OLD_STATUS, where the OLD_ prefix gives access to the old column
		value.
		<programlisting> insert into SYM_ROUTER (router_id,
		source_node_group_id, target_node_group_id, router_type,
		router_expression, create_time, last_update_time) values
		('corp-2-store-status','corp', 'store', 'column', 'STATUS!=:OLD_STATUS',
		current_timestamp, current_timestamp); </programlisting>
		</para>
		
		<para>
		Consider a table that needs to be routed to only nodes in the target
		group whose STORE_ID column matches the external id of a node. The
		following SQL statement will insert a column router to accomplish that.
		<programlisting> insert into SYM_ROUTER (router_id,
		source_node_group_id, target_node_group_id, router_type,
		router_expression, create_time, last_update_time) values
		('corp-2-store-id','corp', 'store', 'column', 'STORE_ID=:EXTERNAL_ID',
		current_timestamp, current_timestamp); </programlisting>
		Attributes on a
		<xref linkend="table_node" xrefstyle="table" />
		that can be referenced with tokens include:
		<itemizedlist>
		<listitem>:NODE_ID</listitem>
		
		<listitem>:EXTERNAL_ID</listitem>
		
		<listitem>:NODE_GROUP_ID</listitem>
		</itemizedlist>
		Captured EXTERNAL_DATA is also available for routing as a virtual
		column.
		</para>
		
		<para>
		Consider a table that needs to be routed to a redirect node defined by
		its external id in the
		<xref linkend="table_registration_redirect" xrefstyle="table" />
		table. The following SQL statement will insert a column router to
		accomplish that.
		<programlisting> insert into SYM_ROUTER (router_id,
		source_node_group_id, target_node_group_id, router_type,
		router_expression, create_time, last_update_time) values
		('corp-2-store-redirect','corp', 'store', 'column',
		'STORE_ID=:REDIRECT_NODE', current_timestamp, current_timestamp); </programlisting>
		</para>
		
		<para>
		More than one column may be configured in a router_expression. When more
		than one column is configured, all matches are added to the list of
		nodes to route to. The following is an example where the STORE_ID column
		may contain the STORE_ID to route to or the constant of ALL which
		indicates that all nodes should receive the update.
		<programlisting> insert into SYM_ROUTER (router_id,
		source_node_group_id, target_node_group_id, router_type,
		router_expression, create_time, last_update_time) values
		('corp-2-store-multiple-matches','corp', 'store', 'column',
		'STORE_ID=ALL or STORE_ID=:EXTERNAL_ID', current_timestamp,
		current_timestamp); </programlisting>
		</para>
		
		<para>
		The NULL keyword may be used to check if a column is null. If the column
		is null, then data will be routed to all nodes who qualify for the
		update. This following is an example where the STORE_ID column is used
		to route to a set of nodes who have a STORE_ID equal to their
		EXTERNAL_ID, or to all nodes if the STORE_ID is null.
		<programlisting> insert into SYM_ROUTER (router_id,
		source_node_group_id, target_node_group_id, router_type,
		router_expression, create_time, last_update_time) values
		('corp-2-store-multiple-matches','corp', 'store', 'column',
		'STORE_ID=NULL or STORE_ID=:EXTERNAL_ID', current_timestamp,
		current_timestamp); </programlisting>
		</para>
		</section>
		
		<section id="configuration-lookup-table-router">
		<title>Lookup Table Router</title>
		
		<para>
		A lookup table may contain the id of the node where data needs to be
		routed. This could be an existing table or an ancillary table that is
		added specifically for the purpose of routing data. Lookup table routers
		are configured by setting the
		<literal>router_type</literal>
		column on the
		<xref linkend="table_router" xrefstyle="table" />
		table to
		<literal>lookuptable</literal>
		and setting a list of configuration parameters in the
		<literal>router_expression</literal>
		column.
		</para>
		
		<para>
		Each of the following configuration parameters are required.
		<variablelist>
		<varlistentry>
		<term>
		<command>LOOKUP_TABLE</command>
		</term>
		
		<listitem>
		<para>This is the name of the lookup table.</para>
		</listitem>
		</varlistentry>
		
		<varlistentry>
		<term>
		<command>KEY_COLUMN</command>
		</term>
		
		<listitem>
		<para>This is the name of the column on the table that is being
		routed. It will be used as a key into the lookup table.</para>
		</listitem>
		</varlistentry>
		
		<varlistentry>
		<term>
		<command>LOOKUP_KEY_COLUMN</command>
		</term>
		
		<listitem>
		<para>This is the name of the column that is the key on the
		lookup table.</para>
		</listitem>
		</varlistentry>
		
		<varlistentry>
		<term>
		<command>EXTERNAL_ID_COLUMN</command>
		</term>
		
		<listitem>
		<para>This is the name of the column that contains the
		external_id of the node to route to on the lookup table.</para>
		</listitem>
		</varlistentry>
		</variablelist>
		</para>
		
		<para>Note that the lookup table will be read into memory and
		cached for the duration of a routing pass for a single channel.</para>
		
		<para>
		Consider a table that needs to be routed to a specific store, but the
		data in the changing table only contains brand information. In this
		case, the STORE table may be used as a lookup table.
		<programlisting> insert into SYM_ROUTER (router_id,
		source_node_group_id, target_node_group_id, router_type,
		router_expression, create_time, last_update_time) values
		('corp-2-store-ok','corp', 'store', 'lookuptable', 'LOOKUP_TABLE=STORE
		KEY_COLUMN=BRAND_ID LOOKUP_KEY_COLUMN=BRAND_ID
		EXTERNAL_ID_COLUMN=STORE_ID', current_timestamp, current_timestamp); </programlisting>
		</para>
		</section>
		
		<section id="configuration-subselect-router">
		<title>Subselect Router</title>
		
		<para>
		Sometimes routing decisions need to be made based on data that is not in
		the current row being synchronized. A 'subselect' router can be used in
		these cases. A 'subselect' is configured with a
		<literal>router_expression</literal>
		that is a SQL select statement which returns a result set of the node
		ids that need routed to. Column tokens can be used in the SQL expression
		and will be replaced with row column data. The overhead of using this
		router type is high because the 'subselect' statement runs for each row
		that is routed. It should not be used for tables that have a lot of rows
		that are updated. It also has the disadvantage that if the data being
		relied on to determine the node id has been deleted before routing takes
		place, then no results would be returned and routing would not happen.
		</para>
		<para>
		The
		<literal>router_expression</literal>
		you specify is appended to the following SQL statement in order to
		select the node ids:
		<programlisting>select c.node_id from sym_node c where
		c.node_group_id=:NODE_GROUP_ID and c.sync_enabled=1 and ... </programlisting>
		<para>
		As you can see, you have access to information about the node currently
		under consideration for routing through the 'c' alias, for example
		<literal>c.external_id</literal>
		. There are two node-related tokens you can use in your expression:
		<itemizedlist>
		<listitem>:NODE_GROUP_ID</listitem>
		<listitem>:EXTERNAL_DATA</listitem>
		</itemizedlist>
		</para>
		Column names representing data for the row in question are prefixed with
		a colon as well, for example:
		
		<literal>:EMPLOYEE_ID</literal>
		, or
		<literal>:OLD_EMPLOYEE_ID</literal>
		. Here, the OLD_ prefix indicates the value before the change in cases
		where the old data has been captured.
		
		</para>
		<para> For an example, consider the case where an Order table and
		an OrderLineItem table need to be routed to a specific store. The Order
		table has a column named order_id and STORE_ID. A store node has an
		external_id that is equal to the STORE_ID on the Order table.
		OrderLineItem, however, only has a foreign key to its Order of order_id.
		To route OrderLineItems to the same nodes that the Order will be routed
		to, we need to reference the master Order record.</para>
		
		<para>
		There are two possible ways to solve this in SymmetricDS. One is to
		configure a 'subselect' router_type on the
		<xref linkend="table_router" xrefstyle="table" />
		table, shown below (The other possible approach is to use an
		<literal>external_select</literal>
		to capture the data via a trigger for use in a column match router,
		demonstrated in
		<xref linkend="configuration-routing-external-select" />
		).
		</para>
		
		<para>
		Our solution utilizing subselect compares the external id of the current
		node with the store id from the Order table where the order id matches
		the order id of the current row being routed:
		<programlisting> insert into SYM_ROUTER (router_id,
		source_node_group_id, target_node_group_id, router_type,
		router_expression, create_time, last_update_time) values
		('corp-2-store','corp', 'store', 'subselect', 'c.external_id in (select
		STORE_ID from order where order_id=:ORDER_ID)', current_timestamp,
		current_timestamp); </programlisting>
		</para>
		
		<para>As a final note, please note in this example that the
		parent row in Order must still exist at the moment of routing for the
		child rows (OrderLineItem) to route, since the select statement is run
		when routing is occurring, not when the change data is first captured. </para>
		
		</section>
		
		<section id="configuration-scripted-router">
		<title>Scripted Router</title>
		
		<para>
		When more flexibility is needed in the logic to choose the nodes to
		route to, then the a scripted router may be used. The currently
		available scripting language is Bean Shell. Bean Shell is a Java-like
		scripting language. Documentation for the Bean Shell scripting language
		can be found at
		<ulink url="http://www.beanshell.org/">http://www.beanshell.org</ulink>
		.
		</para>
		
		<para>
		The router_type for a Bean Shell scripted router is 'bsh'. The
		router_expression is a valid Bean Shell script that:
		<itemizedlist>
		<listitem>
		adds node ids to the
		<code>targetNodes</code>
		collection which is bound to the script
		</listitem>
		
		<listitem>returns a new collection of node ids</listitem>
		
		<listitem>returns a single node id</listitem>
		
		<listitem>returns true to indicate that all nodes should be
		routed or returns false to indicate that no nodes should be routed</listitem>
		</itemizedlist>
		Also bound to the script evaluation is a list of
		<code>nodes</code>
		. The list of
		<code>nodes</code>
		is a list of eligible
		<code>org.jumpmind.symmetric.model.Node</code>
		objects. The current data column values and the old data column values
		are bound to the script evaluation as Java object representations of the
		column data. The columns are bound using the uppercase names of the
		columns. Old values are bound to uppercase representations that are
		prefixed with 'OLD_'.
		</para>
		
		<para>
		If you need access to any of the SymmetricDS services, then the instance
		of
		<code>org.jumpmind.symmetric.ISymmetricEngine</code>
		is accessible via the bound
		<code>engine</code>
		variable.
		</para>
		
		<para>
		In the following example, the node_id is a combination of STORE_ID and
		WORKSTATION_NUMBER, both of which are columns on the table that is being
		routed.
		<programlisting> insert into SYM_ROUTER (router_id,
		source_node_group_id, target_node_group_id, router_type,
		router_expression, create_time, last_update_time) values
		('corp-2-store-bsh','corp', 'store', 'bsh', 'targetNodes.add(STORE_ID +
		"-" + WORKSTATION_NUMBER);', current_timestamp, current_timestamp); </programlisting>
		</para>
		
		<para>
		The same could also be accomplished by simply returning the node id. The
		last line of a bsh script is always the return value.
		<programlisting> insert into SYM_ROUTER (router_id,
		source_node_group_id, target_node_group_id, router_type,
		router_expression, create_time, last_update_time) values
		('corp-2-store-bsh','corp', 'store', 'bsh', 'STORE_ID + "-" +
		WORKSTATION_NUMBER', current_timestamp, current_timestamp); </programlisting>
		</para>
		
		<para>
		The following example will synchronize to all nodes if the FLAG column
		has changed, otherwise no nodes will be synchronized. Note that here we
		make use of OLD_, which provides access to the old column value.
		<programlisting> insert into SYM_ROUTER (router_id,
		source_node_group_id, target_node_group_id, router_type,
		router_expression, create_time, last_update_time) values
		('corp-2-store-flag-changed','corp', 'store', 'bsh', 'FLAG != null
		&amp;&amp; !FLAG.equals(OLD_FLAG)', current_timestamp,
		current_timestamp); </programlisting>
		</para>
		
		<para>
		The next example shows a script that iterates over each eligible node
		and checks to see if the trimmed value of the column named STATION
		equals the external_id.
		<programlisting> insert into SYM_ROUTER (router_id,
		source_node_group_id, target_node_group_id, router_type,
		router_expression, create_time, last_update_time) values
		('corp-2-store-trimmed-station','corp', 'store', 'bsh', 'for
		(org.jumpmind.symmetric.model.Node node : nodes) { if (STATION != null
		&amp;&amp; node.getExternalId().equals(STATION.trim())) {
		targetNodes.add(node.getNodeId()); } }', current_timestamp,
		current_timestamp); </programlisting>
		</para>
		</section>
		
		<section id="configuration-audit-table-router">
		<title>Audit Table Router</title>
		
		<para>
		This router audits captured data by recording the change in an audit
		table that the router creates and keeps up to date (as long as
		<code>auto.config.database</code>
		is set to true.) The router creates a table named the same as the table
		for which data was captured with the suffix of _AUDIT. It will contain
		all of the same columns as the original table with the same data types
		only each column is nullable with no default values.
		</para>
		
		<para>
		Three extra "AUDIT" columns are added to the table:
		<itemizedlist>
		<listitem>AUDIT_ID - the primary key of the table.</listitem>
		<listitem>AUDIT_TIME - the time at which the change occurred.</listitem>
		<listitem>AUDIT_EVENT - the DML type that happened to the
		row.</listitem>
		</itemizedlist>
		</para>
		
		<para>
		The following is an example of an audit router
		<programlisting> insert into SYM_ROUTER (router_id,
		source_node_group_id, target_node_group_id, router_type, create_time,
		last_update_time) values ('audit_at_corp','corp', 'local', 'audit',
		current_timestamp, current_timestamp); </programlisting>
		</para>
		
		<para>The audit router captures data for a group link. For the
		audit router to work it must be associated with a node_group_link with
		an action of type 'R'. The 'R' stands for 'only routes to'. In the above
		example, we refer to a 'corp to local' group link. Here, local is a new
		node_group created for the audit router. No nodes belong to the 'local'
		node_group. If a trigger linked to an audit router fires on the corp
		node, a new audit table will be created at the corp node with the new
		data inserted.</para>
		</section>
		
		
		
		
		<section id="configuration-routing-external-select">
		<title>Utilizing External Select when Routing</title>
		
		
		
		<para>
		There may be times when you wish to route based on a piece of data that
		exists in a table other than the one being routed. The approach, first
		discussed in
		<xref linkend="configuration-subselect-router" />
		, is to utilize an
		<literal>external_select</literal>
		to save away data in
		<literal>external_data</literal>
		, which can then be referenced during routing.
		</para>
		<para>
		Reconsider subselect's Order / OrderLineItem example (found in
		<xref linkend="configuration-subselect-router" />
		), where routing for the line item is accomplished by linking to the
		"header" Order row. As an alternate way of solving the problem, we will
		now use External Select combined with a column match router.
		</para>
		<para>
		In this version of the solution, the STORE_ID is captured from the Order
		table in the EXTERNAL_DATA column when the trigger fires. The router is
		configured to route based on the captured EXTERNAL_DATA to all nodes
		whose external id matches the captured external data.
		<programlisting>insert into SYM_TRIGGER
		(trigger_id,source_table_name,channel_id,external_select,
		last_update_time,create_time) values ('orderlineitem', 'orderlineitem',
		'orderlineitem','select STORE_ID from order where
		order_id=$(curTriggerValue).$(curColumnPrefix)order_id',
		current_timestamp, current_timestamp); insert into SYM_ROUTER
		(router_id, source_node_group_id, target_node_group_id, router_type,
		router_expression, create_time, last_update_time) values
		('corp-2-store-ext','corp', 'store', 'column',
		'EXTERNAL_DATA=:EXTERNAL_ID', current_timestamp, current_timestamp); </programlisting>
		</para>
		
		<para>The following variables can be used with the external select:</para>
		
		<variablelist>
			<varlistentry>
				<term>
		    		<command>$(curTriggerValue)</command>
				</term>	
				<listitem>
		    		<para>
		    		  Variable to be replaced with the NEW or OLD column alias provided by the trigger context, which is platform specific.
		    		  For insert and update triggers, the NEW alias is used; for delete triggers, the OLD alias is used.
		    		  For example, "$(curTriggerValue).COLUMN" becomes ":new.COLUMN" for an insert trigger on Oracle.
		    		</para>
				</listitem>
			</varlistentry>
		
		    <varlistentry>
		        <term>
		            <command>$(curColumnPrefix)</command>
		        </term> 
		        <listitem>
		            <para>
		                Variable to be replaced with the NEW_ or OLD_ column prefix for platforms that don't support column aliases.
		                This is currently only used by the H2 database.  All other platforms will replace the variable with an empty string.
		                For example "$(curColumnPrefix)COLUMN" becomes "NEW_COLUMN" on H2 and "COLUMN" on Oracle.
		            </para>
		        </listitem>
		    </varlistentry>
		</variablelist>
		
		<para>The advantage of this approach over the 'subselect'
		approach is that it guards against the (somewhat unlikely) possibility
		that the master Order table row might have been deleted before routing
		has taken place. This external select solution also is a bit more
		efficient than the 'subselect' approach, although the triggers produced
		do run the extra external_select SQL inline with application database
		updates.</para>
		
		</section>
		
	</section>
	<section id="configuration-conflicts">
	<title>Conflicts</title>
		<xi:include href="conflicts.xml" />
	</section>
	<section id="configuration-transforms">
	<title>Transforms</title>
	
<para>New as of SymmetricDS 2.4, SymmetricDS is now able to
transform synchronized data by way of configuration (previously, for
most cases a custom data loader would need to have been written). This
transformation can take place on a source node or on a target node, as
the data is being loaded or extracted. With this new feature you can,
for example:</para>

<itemizedlist>
<listitem>
<para>Copy a column from a source table to two (or more) target
table columns,</para>
</listitem>

<listitem>
<para>Merge columns from two or more source tables into a single
row in a target table,</para>
</listitem>

<listitem>
<para>Insert constants in columns in target tables based on
source data synchronizations,</para>
</listitem>

<listitem>
<para>Insert multiple rows of data into a single target table
based on one change in a source table,</para>
</listitem>

<listitem>
<para>Apply a Bean Shell script to achieve a custom transform
when loading into the target database.</para>
</listitem>
</itemizedlist>

<para>These transformations can take place either on the target
or on the source, and as data is either being extracted or loaded. In
either case, the transformation is initiated due to existence of a
source synchronization trigger. The source trigger creates the
synchronization data, while the transformation configuration decides
what to do with the synchronization data as it is either being extracted
from the source or loaded into the target. You have the flexibility of
defining different transformation behavior depending on whether the
source change that triggered the synchronization was an Insert, Update,
or Delete. In the case of Delete, you even have options on what exactly
to do on the target side, be it a delete of a row, setting columns to
specific values, or absolutely nothing at all.</para>

<para>A few key concepts are important to keep in mind to
understand how SymmetricDS performs transformations. The first concept
is that of the "source operation" or "source DML type", which is the
type of operation that occurred to generate the synchronization data in
the first place (i.e., an insert, a delete, or an update). Your
transformations can be configured to act differently based on the source
DML type, if desired. When transforming, by default the DML action taken
on the target matches that of the action taken on the row in the source
(although this behavior can be altered through configuration if needed).
If the source DML type is an Insert, for example, the resulting
transformation DML(s) will be Insert(s).</para>

<para>Another important concept is the way in which transforms
are applied. Each source operation may map to one or more transforms and
result in one or more operations on the target tables. Each of these
target operations are performed as independent operations in sequence
and must be "complete" from a SQL perspective. In other words, you must
define columns for the transformation that are sufficient to fill in any
primary key or other required data in the target table if the source
operation was an Insert, for example.</para>

<para>Please note that the transformation engine relies
on a source trigger / router existing to supply the source data for the
transformation. The transform configuration will never be used if the
source table and target node group does not have a defined trigger /
router combination for that source table and target node group.</para>

<section id="transform-data-tables">
<title>Transform Configuration Tables</title>

<para>
SymmetricDS stores its transformation configuration in two configuration
tables,
<xref linkend="table_transform_table" xrefstyle="table" />
and
<xref linkend="table_transform_column" xrefstyle="table" />
. Defining a transformation involves configuration in both tables, with
the first table defining which source and destination tables are
involved, and the second defining the columns involved in the
transformation and the behavior of the data for those columns. We will
explain the various options available in both tables and the various
pre-defined transformation types.
<!--  and then end with a series of examples.-->
</para>

<para>
To define a transformation, you will first define the source table and
target table that applies to a particular transformation. The source and
target tables, along with a unique identifier (the transform_id column)
are defined in
<xref linkend="table_transform_table" xrefstyle="table" />
. In addition, you will specify the source_node_group_id and
target_node_group_id to which the transform will apply, along with
whether the transform should occur on the Extract step or the Load step
(transform_point). All of these values are required.
</para>

<para>
Three additional configuration settings are also defined at the
source-target table level: the order of the transformations, the
behavior when deleting, and whether an update should always be attempted
first. More specifically,
<itemizedlist>
<listitem>transform_order: For a single source operation that
is mapped to a transformation, there could be more than one target
operation that takes place. You may control the order in which the
target operations are applied through a configuration parameter defined
for each source-target table combination. This might be important, for
example, if the foreign key relationships on the target tables require
you to execute the transformations in a particular order.</listitem>

<listitem>
column_policy: Indicates whether unspecified columns are passed thru or
if all columns must be explicitly defined. The options include:
<itemizedlist>
<listitem>SPECIFIED - Indicates that only the transform
columns that are defined will be the ones that end up as part of the
transformation.</listitem>

<listitem>IMPLIED - Indicates that if not specified, then
columns from the source are passed through to the target. This is useful
if you just want to map a table from one name to anther or from one
schema to another. It is also useful if you want to transform a table,
but also want to pass it through. You would define an implied transform
from the source to the target and would not have to configure each
column.</listitem>
</itemizedlist>
</listitem>

<listitem>
delete_action: When a source operation of Delete takes place, there are
three possible ways to handle the transformation at the target. The
options include:
<itemizedlist>
<listitem>NONE - The delete results in no target changes.</listitem>

<listitem>DEL_ROW - The delete results in a delete of the row
as specified by the pk columns defined in the transformation
configuration.</listitem>

<listitem>UPDATE_COL - The delete results in an Update
operation on the target which updates the specific rows and columns
based on the defined transformation.</listitem>
</itemizedlist>
</listitem>

<listitem>
update_first: This option overrides the default behavior for an Insert
operation. Instead of attempting the Insert first, SymmetricDS will
always perform an Update first and then fall back to an Insert if that
fails. Note that, by default, fall back logic
<emphasis>always</emphasis>
applies for Insert and Updates. Here, all you a specifying is whether to
always do an Update first, which can have performance benefits under
certain situations you may run into.
</listitem>
</itemizedlist>
</para>

<para>
For each transformation defined in
<xref linkend="table_transform_table" xrefstyle="table" />
, the columns to be transformed (and how they are transformed) are
defined in
<xref linkend="table_transform_column" xrefstyle="table" />
. This column-level table typically has several rows for each
transformation id, each of which defines the source column name, the
target column name, as well as the following details:
<itemizedlist>
<listitem>include_on: Defines whether this entry applies to
source operations of Insert (I), Update (U), or Delete (D), or any
source operation.</listitem>

<listitem>pk: Indicates that this mapping is used to define
the "primary key" for identifying the target row(s) (which may or may
not be the true primary key of the target table). This is used to define
the "where" clause when an Update or Delete on the target is occurring.
At least one row marked as a pk should be present for each transform_id.</listitem>

<listitem>transform_type, transform_expression: Specifies how
the data is modified, if at all. The available transform types are
discussed below, and the default is 'copy', which just copies the data
from source to target.</listitem>

<listitem>transform_order: In the event there are more than
one columns to transform, this defines the relative order in which the
transformations are applied.</listitem>
</itemizedlist>
</para>
</section>

<section id="transform-data-types">
<title>Transformation Types</title>
	<para>
	There are several pre-defined transform types available in SymmetricDS.
	Additional ones can be defined by creating and configuring an extension
	point which implements the
	<code>IColumnTransform</code>
	interface. The pre-defined transform types include the following (the
	transform_type entry is shown in parentheses):
	<itemizedlist>
	<listitem><emphasis role="bold">Copy Column Transform ('copy')</emphasis>: This transformation
	type copies the source column value to the target column. This is the
	default behavior.</listitem>
	
	<listitem><emphasis role="bold">Remove Column Transform ('remove')</emphasis>: This
	transformation type removes the source column. This transform type is
	only valid for a table transformation type of 'IMPLIED' where all the
	columns from the source are automatically copied to the target.</listitem>
	
	<listitem><emphasis role="bold">Constant Transform ('const')</emphasis>: This transformation
	type allows you to map a constant value to the given target column. The
	constant itself is placed in transform_expression.</listitem>
	
	<listitem>
	<emphasis role="bold">Variable Transform ('variable')</emphasis>: This transformation type allows you to
	map a built-in dynamic variable to the given target column. The variable
	name is placed in transform_expression. The following variables are
	available:
	<code>system_date</code>
	is the current system date,
	<code>system_timestamp</code>
	is the current system date and time,
	<code>source_node_id</code>
	is the node id of the source,
	<code>target_node_id</code>
	is the node id of the target,
	<code>null</code>
	is a null value, and <code>old_column_value</code> is the column's old value prior to the DML operation,
    <code>source_table_name</code>
    is the name of the source table as captured in the trigger hist table,
    <code>source_catalog_name</code>
    is the name of the source catalog as captured in the trigger hist table,
    <code>source_schema_name</code>
    is the name of the source schema as captured in the trigger hist table.
	</listitem>
	
	<listitem><emphasis role="bold">Additive Transform ('additive')</emphasis>: This
	transformation type is used for numeric data. It computes the change
	between the old and new values on the source and then adds the change to
	the existing value in the target column. That is, target = target +
	multiplier (source_new - source_old), where multiplier is a constant
	found in the transform_expression (default is 1 if not specified). For
	example, if the source column changed from a 2 to a 4, the target column
	is currently 10, and the multiplier is 3, the effect of the transform
	will be to change the target column to a value of 16 ( 10+3*(4-2) =&gt;
	16 ). Note that, in the case of deletes, the new column value is
	considered 0 for the purposes of the calculation.</listitem>
	
	<listitem>
	<emphasis role="bold">Substring Transform ('substr')</emphasis>: This transformation computes a substring
	of the source column data and uses the substring as the target column
	value. The transform_expression can be a single integer (
	<code>n</code>
	, the beginning index), or a pair of comma-separated integers (
	<code>n,m</code>
	- the beginning and ending index). The transform behaves as the Java
	substring function would using the specified values in
	transform_expression.
	</listitem>
	
	<listitem><emphasis role="bold">Multiplier Transform ('multiply')</emphasis>: This
	transformation allows for the creation of multiple rows in the target
	table based on the transform_expression. This transform type can only be
	used on a primary key column. The transform_expression is a SQL
	statement that returns the list to be used to create the multiple
	targets.</listitem>
	
	<listitem><emphasis role="bold">Lookup Transform ('lookup')</emphasis>: This transformation
	determines the target column value by using a query, contained in
	transform_expression to lookup the value in another table. The query
	must return a single row, and the first column of the query is used as
	the value. Your query references source column names by prefixing with a
	colon (e.g., :MY_COLUMN).</listitem>
	
	<listitem>
	<emphasis role="bold">BeanShell Script Transform ('bsh')</emphasis>: This transformation allows you to
	provide a Bean Shell script in transform_expression and executes the
	script at the time of transformation. Some variables are provided to the
	script:
	<code>COLUMN_NAME</code>
	is a variable for a source column in the row, where the variable name is
	the column name in uppercase;
	<code>currentValue</code>
	is the value of the current source column;
	<code>oldValue</code>
	is the old value of the source column for an updated row;
	<code>sqlTemplate</code>
	is a
	<code>org.jumpmind.db.sql.ISqlTemplate</code>
	object for querying or updating the database;
	<code>channelId</code>
	is a reference to the channel on which the transformation is happening;
	<code>sourceNode</code>
	is a
	<code>org.jumpmind.symmetric.model.Node</code>
	object that represents the node from where the data came;
	<code>targetNode</code>
	is a
	<code>org.jumpmind.symmetric.model.Node</code>
	object that represents the node where the data is being loaded.
	</listitem>

    <listitem>
    <emphasis role="bold">Java Transform ('java')</emphasis>: Use Java code in the transform expression that is included in the
    transform method of a class that extends JavaColumnTransform.  The class is compiled 
    whenever the transform expression changes and kept in memory for runtime.
    The code must return a String for the new value of the column being mapped. 
    The following variables are available:
    <code>platform</code>
    is the IDatabasePlatform that contains objects for the database platform, such as
    DatabaseInfo, IDdlReader, IDdlBuilder, and ISqlTemplate. 
    <code>context</code>
    is the DataContext that contains information about current row and the data loader session, such as
    Batch, Table, and CsvData. 
    <code>column</code>
    is the TransformColumn that contains information from the TRANSFORM_COLUMN configuration.
    <code>data</code>
    is the TransformedData that contains information about the source and target values being transformed,
    including the TransformTable.
    <code>sourceValues</code>
    is a Map&lt;String, String&gt; contain all source column values for the row.
    <code>newValue</code>
    is a String for the new value of the column.
    <code>oldValue</code>
    is a String for the old value of the column if the event is an update or delete.
    </listitem>
	
	<listitem><emphasis role="bold">Identity Transform ('identity')</emphasis>: This
	transformation allows you to insert into an identity column by computing
	a new identity, not copying the actual identity value from the source.
	</listitem>
	
	<listitem>
	<emphasis role="bold">Mathematical Transform ('math')</emphasis>: This transformation allows you to 
	perform mathematical equations in the transform expression. Some 
	variables are provided to the script:
	<code>#{COLUMN_NAME}</code>
	is a variable for a source column in the row, where the variable name
	is the column name in uppercase;
	<code>#{currentValue}</code>
	is the value of the current source column;
	<code>#{oldValue}</code>
	is the old value of the source column for an updated row.
	</listitem>
	
	<listitem>
	<emphasis role="bold">Copy If Changed Transform ('copyIfChanged')</emphasis>:  This transformation will copy the value to the target column if the source value has changed.  More
	specifically, the copy will occur if the the old value of the source does not equal the new value.  If the old and new are, in fact, equal, then either
	the column will be ignored or the row will be ignored, based on the setting of the transform expression.  If the transform expression is euqal
	to the string 'IgnoreColumn', the column will be ignored; otherwise, the row will be ignored.
	</listitem>
	
	
	<listitem>
	<emphasis role="bold">Value Map Transform ('valueMap')</emphasis>:  This transformation allows for simple value substitutions through use of the transform expression.
	The transform expresion should consist of a space separated list of value pairs of the format sourceValue=TargetValue.  The column value is used to 
	locate the correct sourceValue, and the transform will change the value into the corresponding targetValue.  A sourceValue of * can be used to
	represent a default target value in the event that the sourceValue is not found.  Otherwise, if no default value is found,
	the result will be null.  For example, consider the following transform expression:  s1=t1 s2=t2 s3=t3 *=t4.  A source value of
	s1 will be transformed to t1, s2 to t2, s3 to t3, s4 to t4, s5 to t4, null to t4, etc.
	</listitem>
	
	<listitem>
	<emphasis role="bold">Clarion Date Time ('clarionDateTime')</emphasis>:  Convert a Clarion date with optional time into a timestamp.  Clarion dates are stored as the number of days
	since December 28, 1800, while Clarion times are stored as hundredths of a second since midnight, plus one.  Use a source column of the Clarion date
	and a target column of the timestamp.  Optionally, in the transform expression, enter the name of the Clarion time column.
	</listitem>
	
	<listitem>
	<emphasis role="bold">Columns To Rows ('columnsToRowsKey' and 'columnsToRowsValue')</emphasis>:  Convert column values from a single source row into a row per column value
	at the target.  Two column mappings are needed to complete the work: use "columnsToRowsKey" to map which source column is used,
	and use "columnsToRowsValue" to map the value.  The "columnsToRowsKey" mapping requires an expression in the format of
	"column1=key1,column2=key2" to list the source column names and which key value is stored in the target column.
	The "columnsToRowsValue" mapping sets the column's value at the target and allows an optional expression: 
	"changesOnly=true" to convert only rows when the old and new values have changed; "ignoreNulls=true" to convert only rows that are not null. 
	For example, column "fieldid" mapped as "columnsToRowsKey" with expression of "user1=1,user2=2" and column "color" mapped as
	"columnsToRowsValue" would convert a row with columns named "user1" and "user2" containing values "red" and "blue" into two rows with columns
	"fieldid" and "color" containing a row of "1" and "red" and a row of "2" and "blue". 
	</listitem>

	</itemizedlist>
	</para>
	</section>
	</section>
	<section id="configuration-load-filters">
		<title>Load Filters</title>
		<para>
		New as of SymmetricDS 3.1, SymmetricDS is now capable of taking actions
		upon the load of certain data via configurable load filters. This new
		configurable option is in additon to the already existing option of
		writing a class that implements
		<xref linkend="extensions-data-loader-filter" xrefstyle="table" />
		. A configurable load filter watches for specific data that is being
		loaded and then takes action based on the load of that data.
		</para>
		
		<para>Specifying which data to action is done by specifying a
		souce and target node group (data extracted from this node group, and
		loaded into that node group), and a target catalog, schema and table
		name. You can decide to take action on rows that are inserted, updated
		and/or deleted, and can also further delineate which rows of the target
		table to take action on by specifying additional criteria in the bean
		shell script that is executed in response to the loaded data. As an
		example, old and new values for the row of data being loaded are
		available in the bean shell script, so you can action rows with a
		certain column value in old or new data.</para>
		
		<para>The action taken is based on a bean shell script that you
		can provide as part of the configuration. Actions can be taken at
		different points in the load process including before write, after
		write, at batch complete, at batch commit and/or at batch rollback.</para>
		
		<section id="data-load-filter-config">
		<title>Load Filter Configuration Table</title>
		
		<para>
		SymmetricDS stores its load filter configuration in a single table
		called
		<xref linkend="table_load_filter" xrefstyle="table" />
		. The load filter table allows you to specify the following:
		<itemizedlist>
		<listitem>Load Filter Type ('load_filter_type'): The type of
		load filter. Today only Bean Shell is supported ('BSH'), but SQL scripts
		may be added in a future release.</listitem>
		
		<listitem>Source Node Group ('source_node_group_id'): The
		source node group for which you would like to watch for changes.</listitem>
		
		<listitem>Target Node Group ('target_node_group_id'): The
		target node group for which you would like to watch for changes. The
		source and target not groups are used together to identify the node
		group link for which you would like to watch for changes (i.e. When the
		Server node group sends data to a Client node group).</listitem>
		
		<listitem>Target Catalog ('target_catalog_name'): The name of
		the target catalog for which you would like to watch for changes.</listitem>
		
		<listitem>Target Schema ('target_schema_name'): The name of
		the target schema for which you would like to watch for changes.</listitem>
		
		<listitem>Target Table ('target_table_name'): The name of the
		target table for which you would like to watch for changes. The target
		catalog, target schema and target table name are used together to fully
		qualify the table for which you would like to watch for changes.</listitem>
		
		<listitem>Filter on Update ('filter_on_update'): Determines
		whether the load filter takes action (executes) on a database update
		statement.</listitem>
		
		<listitem>Filter on Insert ('filter_on_insert'): Determines
		whether the load filter takes action (executes) on a database insert
		statement.</listitem>
		
		<listitem>Filter on Delete ('filter_on_delete'): Determines
		whether the load filter takes action (executes) on a database delete
		statement.</listitem>
		
		<listitem>Before Write Script ('before_write_script'): The
		script to execute before the database write occurs.</listitem>
		
		<listitem>After Write Script ('after_write_script'): The
		script to execute after the database write occurs.</listitem>
		
		<listitem>Batch Complete Script ('batch_complete_script'):
		The script to execute after the entire batch completes.</listitem>
		
		<listitem>Batch Commit Script ('batch_commit_script'): The
		script to execute after the entire batch is committed.</listitem>
		
		<listitem>Batch Rollback Script ('batch_rollback_script'):
		The script to execute if the batch rolls back.</listitem>
		
		<listitem>Handle Error Script ('handle_error_script'): A
		script to execute if data cannot be processed.</listitem>
		
		<listitem>Load Filter Order ('load_filter_order'): The order
		in which load filters should execute if there are multiple scripts
		pertaining to the same source and target data.</listitem>
		</itemizedlist>
		</para>
		</section>
		
		<section id="data-load-filter-variables">
		<title>Variables available to Data Load Filters</title>
		
		<para>
		As part of the bean shell load filters, SymmetricDS provides certain
		variables for use in the bean shell script. Those variables include:
		<itemizedlist>
		<listitem>Symmetric Engine ('ENGINE'): The Symmetric engine
		object.</listitem>
		
		<listitem>Source Values ('&lt;COLUMN_NAME&gt;'): The source
		values for the row being inserted, updated or deleted.</listitem>
		
		<listitem>Old Values ('OLD_&lt;COLUMN_NAME&gt;'): The old
		values for the row being inserted, updated or deleted.</listitem>
		
		<listitem>Data Context ('CONTEXT'): The data context object
		for the data being inserted, updated or deleted. .</listitem>
		
		<listitem>Table Data ('TABLE'): The table object for the
		table being inserted, updated or deleted.</listitem>
		</itemizedlist>
		</para>
		</section>
		
		<section id="data-load-filter-examples">
		<title>Data Load Filter Example</title>
		
		<para>
		The following is an example of a load filter that watches a table named
		TABLE_TO_WATCH being loaded from the Server Node Group to the Client
		Node Group for inserts or updates, and performs an initial load on a
		table named "TABLE_TO_RELOAD" for KEY_FIELD on the reload table equal to
		a column named KEY_FIELD on the TABLE_TO_WATCH table.
		<programlisting> insert into sym_load_filter
		(LOAD_FILTER_ID, LOAD_FILTER_TYPE, SOURCE_NODE_GROUP_ID,
		TARGET_NODE_GROUP_ID, TARGET_CATALOG_NAME, TARGET_SCHEMA_NAME,
		TARGET_TABLE_NAME, FILTER_ON_UPDATE, FILTER_ON_INSERT, FILTER_ON_DELETE,
		BEFORE_WRITE_SCRIPT, AFTER_WRITE_SCRIPT, BATCH_COMPLETE_SCRIPT,
		BATCH_COMMIT_SCRIPT, BATCH_ROLLBACK_SCRIPT, HANDLE_ERROR_SCRIPT,
		CREATE_TIME, LAST_UPDATE_BY, LAST_UPDATE_TIME, LOAD_FILTER_ORDER,
		FAIL_ON_ERROR) values
		('TABLE_TO_RELOAD','BSH','Client','Server',NULL,NULL,
		'TABLE_TO_WATCH',1,1,0,null,
		'engine.getDataService().reloadTable(context.getBatch().getSourceNodeId(),
		table.getCatalog(), table.getSchema(), "TABLE_TO_RELOAD","KEY_FIELD=''"
		+ KEY_FIELD + "''");'
		,null,null,null,null,sysdate,'userid',sysdate,1,1); </programlisting>
		</para>
		</section>
	</section>
	<section id="configuration-grouplets">
		<title>Grouplets</title>
		<para>
        As you probably know by now, SymmetricDS stores its single configuration centrally and distributes it to all nodes.   By default, a trigger-router is in effect for all nodes in the source node group or target node group.  Triggers will be established
        on each node that is a member of the source node, and changes will be routed to all relevant nodes that are members of the target node group.  If, for example, the router routes to "all" nodes,
        "all" means every node that is in the target node group.  This is the default behavior of SymmetricDS.
        </para>
        <para>
        Once in production, however, you will likely find you need or want to make configuration changes to triggers and routers as new features are rolled out to your network of SymmetricDS nodes.
        You may, for example, wish to "pilot" a new configuration, containing new synchronizations, only on specific nodes initially, and then increase the size of the pilot over time.
        SymmetricDS' does provide the ability to specify that only particular trigger-router combinations are applicable to particular nodes for this purpose.  It does this
        by allowing you to define an arbitray collection of nodes, called a "grouplet", and then choosing which trigger-routers apply to the normal set of nodes (the default behavior)
        and which apply just to nodes in one or more "grouplets".  This allows you, essentially, to filter the list of nodes that would otherwise be included as source nodes and/or target nodes.
        Through the use of grouplets, you can, for example, specify a subset of nodes on which a given trigger would be created.  It also allows you to
        specify a subset of the normal set of nodes a change would be routed to.  This behaviour is in addition to, and occurs before, any subsetting or filtering the router might otherwise do.
        </para>
        <para>
        In its simplest form, a grouplet is just an arbitrary collection of nodes.  To define a grouplet, you start by creating a grouplet with a unique id, a description, and a link policy,
        as defined in  <xref linkend="table_grouplet" xrefstyle="table"/>.  To defined which nodes are members of (or are not members of) a grouplet, you provide a list of external ids of the nodes
        in <xref linkend="table_grouplet_link" xrefstyle="table"/>.  How those external ids are used varies based on the grouplet link policy.
        The <literal>grouplet_link_policy</literal> can be either I or E, representing an "inclusive" list of nodes or an "exclusive" list of
        nodes, respectively.  In the case of "inclusive", you'll be listing each external id to be included in the grouplet.  In the case of exclusive, all nodes will be included in
        the grouplet <emphasis>except</emphasis> ones which have an external id in the list of external ids.
        </para>

        <para>
        Once you have defined your grouplet and which nodes are members of a grouplet, you can tie a grouplet to a given trigger-router through
        the use of <xref linkend="table_trigger_router_grouplet" xrefstyle="table"/>.
        If a particular trigger-router does not appear in this table, SymmetricDS behaves as normal.
        If, however, an entry for a particular trigger-router appears in this table,  the default behavior is overridden based on the <literal>grouplet_id</literal> and <literal>applies_when</literal> settings.
        The grouplet id provides the node list, and the <literal>applies_when</literal> indicates whether the grouplet nodes are to be used to filter the source node list, the target node list,
        or both (settings are "S", "T", and "B", respectively).  Nodes that survive the filtering process on as a source will have a trigger defined, and nodes that survive the filtering process
        as a target are eligible nodes that can be routed to.</para>
         <section id="grouplet-example">
            <title>Grouplet Example</title>

        <para>

        At this point, an example would probably be useful.  Picture the case where you have 100 retail stores (each containing one database, and each a member of the "store" node group)
        and a central office database (external id of corp, and a member of the "corp" node group ). You wish to pilot two new trigger and routers
        for a new feature on your point-of-sale software (one which moves data from corp to store, and one which moves data from store to corp), but you only want the triggers to be installed on 10 specific stores that represent your "pilot" stores.  In this case,
        the simplest approach would be to define a grouplet with, say, a grouplet id of "pilot".  We'd use a grouplet link policy of "inclusive", and list each of the 10 external ids
        in the <xref linkend="table_grouplet_link" xrefstyle="table"/> table.
        </para>
        <para>
        For the trigger-router meant to send data from corp to store, we'd create an entry in <xref linkend="table_trigger_router_grouplet" xrefstyle="table"/> for
        our grouplet id of "pilot", and we'd specify "T" (target) as the applies-when setting.  In this way, the source node list is not filtered, but the target node list used during routing
        will filter the potential target nodes to just our pilot stores.  For the trigger-router meant to send data from a pilot store back to corp, we would have the grouplet apply when
        the node is in the source node list (i.e., <literal>applies_when</literal> will be "S").  This will cause the trigger to only be created for stores in the pilot list and not other stores.
        </para>
        <para>An important thing to mention in this example:  Since your grouplet only included the store nodes, you can't simply specify "both" for the applies when setting.  For the corp-to-store trigger,
        for example, if you had said "both", no trigger would have been installed in corp since the grouplet nodes represent all possible source nodes as well as target nodes, and "corp" is not in the list!
        The same is true for the store to corp trigger-router as well.  You could, however, use "both" as the applies when if you had included the "corp" external id in with the list of the 10 pilot store external ids.
        </para>
     </section>
	</section>
	<section id="configuration-parameters">
		<title>Parameters</title>
		<para>Parameters can be used to help tune and configure your SymmetricDS configuration.  Parameters can be set for an individual node or for all nodes in your network.</para>
		<para>See <xref linkend="parameters"/>, for a complete list of parameters.</para>
	</section>
	<section id="configuration-export">
	<title>Export</title>
	</section>
	<section id="configuration-import">
	<title>Import</title>
	</section>
	<section id="configuration-uninstall">
	<title>Uninstall</title>
	</section>
	

</chapter>
