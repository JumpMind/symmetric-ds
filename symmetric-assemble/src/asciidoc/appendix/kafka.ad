
=== Kafka

Use `symadmin module install kafka` to install driver files, or copy your own files into the `lib` sub-directory.

Send changes from your relational database to Kafka in a variety of formats.  A Kafka node can be setup as a <<Write Only Node>> to receive changes from another node that is capturing changes.

ifdef::pro[]
Setup the Kafka node by using the <<Add Node,Connect Database>> wizard and selecting Kafka as the type.   The URL will be the connection point to Kafka.  User and password are not needed (or used).

image::images/appendix/kafka-node-setup.png[]

After hitting next you can setup advanced options for your Kafka node.

image::images/appendix/kafka-advanced-settings.png[]
endif::pro[]

==== Output Message Format


.Set the output message format with the following property
----
kafka.format=JSON|XML|AVRO|CSV
----


[horizontal]        
JSON::  Json formatted output message 
[source, json]
----
{
  "table name": {
    "eventType": "INSERT|UPDATE|DELETE",
    "data": {
      "column name": "value",....
    }
  }
}    
----
XML::  Xml formatted output message
[source, xml]
----
<row entity="table name" dml="INSERT|UPDATE|DELETE">
	<data key="column name">value</data>
	...
</row>
----
AVRO::  Apache Avro output message (Avro Schema Below)
[source, avro]
----
{
  "type": "record",
  "name": "cdc",
  "fields": [
    {
      "name": "table",
      "type": "string"
    },
    {
      "name": "eventType",
      "type": "string"
    },
    {
      "name": "data",
      "type": {
        "type": "array",
        "items": {
          "name": "column",
          "type": "record",
          "fields": [
            {
              "name": "name",
              "type": "string"
            },
            {
              "name": "value",
              "type": [
                "null",
                "string"
              ]
            }
          ]
        }
      }
    }
  ]
}
----
CSV::  CSV formatted output message
[source, csv]
----
TABLE,table name,EVENT,INSERT|UPDATE|DELETE,column name,value, ...
----

==== Setting the Topic


.Set the topic using the following property
----
kafka.topic.by=CHANNEL|TABLE
----


[horizontal]        
CHANNEL::  This will send to a topic based on the channel of the batch that is being sent.
TABLE:: This will send to a topic based on the table name of the change.

==== Setting Messages By


.Set following property to determine how messages will be sent.
----
kafka.message.by=BATCH|ROW
----


[horizontal]        
BATCH::  This will send one message for each batch containing all changes.
ROW:: This will send one messsage for each change captured.

==== Setting The Producer


.Set following property to specify the producer of the messages.
----
kafka.producer=myapplication
----


ifdef::pro[]
Provide a value for the producer of the message.
endif::pro[]


==== Using a Confluent AVRO Schema Registry

====
NOTE: The message format must be AVRO for this option to work.
====

.Set following property to a Confluent registry.
----
kafka.confluent.registry.url
----

.Set following property to the base java package that contains the java POJOs that implement the org.apache.avro.generic.IndexedRecord. 
----
kafka.avro.java.package
----

====
NOTE: The jar file containing the AVRO generated POJO java beans must be placed in the /lib or /patches folder of SymmetricDS and then a restart is required.
====

==== Using Authentication

Any engine property prefixed with `kafkaclient` will be passed through to the Kafka client producer.
Here is an example of authentication over SSL.

----
kafkaclient.security.protocol=SASL_SSL
kafkaclient.sasl.mechanism=PLAIN
kafkaclient.sasl.jaas.config=org.apache.kafka.common.security.plain.PlainLoginModule required username="myuser" password="mypassword";
----
